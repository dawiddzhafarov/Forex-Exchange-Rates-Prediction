{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCQ7MWL9EB5h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from itertools import chain\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#import keras_tuner as kt\n",
        "df = pd.read_csv(\"drive/MyDrive/Engineer's Project/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYEcjbqBEGfp",
        "outputId": "cf9c3b43-2956-4915-8dae-2807eba778e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       2010.11.15\n",
              "1       2010.11.16\n",
              "2       2010.11.17\n",
              "3       2010.11.18\n",
              "4       2010.11.19\n",
              "           ...    \n",
              "3537    2022.03.27\n",
              "3538    2022.03.28\n",
              "3539    2022.03.29\n",
              "3540    2022.03.30\n",
              "3541    2022.03.31\n",
              "Name: Date, Length: 3542, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "df.pop('usa_cpi')\n",
        "df.pop('pol_cpi')\n",
        "df.pop('usa_inter')\n",
        "df.pop('pol_inter')\n",
        "df.pop('Date')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Kpn6cgfEJAH"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "df_numpy = df.to_numpy() \n",
        "#len(df_numpy[:2500])\n",
        "scaler1 = scaler.fit(df_numpy[:3000])\n",
        "df_scalled = scaler1.transform(df_numpy)\n",
        "#df_scaled_all = scaler.\n",
        "df_scalled = pd.DataFrame(df_scalled, columns=[\n",
        "  'Opening', 'High', 'Low', 'Closing','Momentum', 'Range', 'ohlc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Bj1udUdEKGL"
      },
      "outputs": [],
      "source": [
        "lookback = 15\n",
        "step = 1\n",
        "delay = 0\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6xaTInqELWH"
      },
      "outputs": [],
      "source": [
        "float_data = np.array(df_scalled).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NY_O0oi7ENwD"
      },
      "outputs": [],
      "source": [
        "def generator(data, lookback, delay, min_index, max_index,shuffle=False, batch_size=128, step=1):\n",
        "  if max_index is None:\n",
        "    max_index = len(data) - delay - 1\n",
        "  i = min_index + lookback\n",
        "  while 1:\n",
        "    if shuffle:\n",
        "      rows = np.random.randint(\n",
        "        min_index + lookback, max_index, size=batch_size)\n",
        "    else:\n",
        "      if i + batch_size >= max_index:\n",
        "        i = min_index + lookback\n",
        "      rows = np.arange(i, min(i + batch_size, max_index))\n",
        "      i += len(rows)\n",
        "    samples = np.zeros((len(rows),lookback // step,data.shape[-1]))\n",
        "    targets = np.zeros((len(rows),))\n",
        "    for j, row in enumerate(rows):\n",
        "      indices = range(rows[j] - lookback, rows[j], step)\n",
        "      samples[j] = data[indices]\n",
        "      targets[j] = data[rows[j] + delay][3] \n",
        "    yield samples, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk-ldxRtEP2u"
      },
      "outputs": [],
      "source": [
        "train_gen = generator(float_data,\n",
        "lookback=lookback,\n",
        "delay=delay,\n",
        "min_index=0,\n",
        "max_index=2501,\n",
        "#shuffle=True,\n",
        "step=step,\n",
        "batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fbs-odkeEQ6T"
      },
      "outputs": [],
      "source": [
        "val_gen = generator(float_data,\n",
        "lookback=lookback,\n",
        "delay=delay,\n",
        "min_index=2501,\n",
        "max_index=3001,\n",
        "step=step,\n",
        "batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dvMBTmsER6J"
      },
      "outputs": [],
      "source": [
        "test_gen = generator(float_data,\n",
        "lookback=lookback,\n",
        "delay=delay,\n",
        "min_index=3001,\n",
        "max_index=3543,\n",
        "step=step,\n",
        "batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfFHpPVJES_p"
      },
      "outputs": [],
      "source": [
        "train_steps = (2501 - lookback)\n",
        "val_steps = (3001 - 2501 - lookback)\n",
        "test_steps = (3543 - 3001 - lookback)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "5A9W0nE9cvwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20 epok - 0.03 <br>\n",
        "100 - 0.0195 <br>\n",
        "200  - 0.0147 <br>\n",
        "300 -  0.0184 <br>\n",
        "400 - 0.0149<br>\n",
        "600 - 0.0213<br>\n",
        "wszystko z dropout 0<br>"
      ],
      "metadata": {
        "id": "zm84sRdB40k-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "z prawid≈Çowym delay\n",
        "200 epok - 0.0111!"
      ],
      "metadata": {
        "id": "edABWaMbdVY4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpcL5klxEU9w",
        "outputId": "289fb4e8-4549-4761-ccd8-e7161012cda9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "200/200 [==============================] - 25s 108ms/step - loss: 0.1933 - val_loss: 0.0715\n",
            "Epoch 2/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0600 - val_loss: 0.1871\n",
            "Epoch 3/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0504 - val_loss: 0.0548\n",
            "Epoch 4/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0476 - val_loss: 0.0551\n",
            "Epoch 5/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0424 - val_loss: 0.0318\n",
            "Epoch 6/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0381 - val_loss: 0.0262\n",
            "Epoch 7/200\n",
            "200/200 [==============================] - 16s 80ms/step - loss: 0.0357 - val_loss: 0.0164\n",
            "Epoch 8/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0325 - val_loss: 0.0450\n",
            "Epoch 9/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0304 - val_loss: 0.0510\n",
            "Epoch 10/200\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 0.0286 - val_loss: 0.0725\n",
            "Epoch 11/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0272 - val_loss: 0.0303\n",
            "Epoch 12/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0257 - val_loss: 0.0380\n",
            "Epoch 13/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0254 - val_loss: 0.0149\n",
            "Epoch 14/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0234 - val_loss: 0.0459\n",
            "Epoch 15/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0242 - val_loss: 0.0373\n",
            "Epoch 16/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0223 - val_loss: 0.0329\n",
            "Epoch 17/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0225 - val_loss: 0.0082\n",
            "Epoch 18/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0211 - val_loss: 0.0077\n",
            "Epoch 19/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0208 - val_loss: 0.0254\n",
            "Epoch 20/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0203 - val_loss: 0.0064\n",
            "Epoch 21/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0201 - val_loss: 0.0224\n",
            "Epoch 22/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0192 - val_loss: 0.0366\n",
            "Epoch 23/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0188 - val_loss: 0.0084\n",
            "Epoch 24/200\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.0186 - val_loss: 0.0260\n",
            "Epoch 25/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0180 - val_loss: 0.0145\n",
            "Epoch 26/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0177 - val_loss: 0.0081\n",
            "Epoch 27/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0173 - val_loss: 0.0272\n",
            "Epoch 28/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0170 - val_loss: 0.0320\n",
            "Epoch 29/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0166 - val_loss: 0.0112\n",
            "Epoch 30/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0165 - val_loss: 0.0239\n",
            "Epoch 31/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0159 - val_loss: 0.0176\n",
            "Epoch 32/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0159 - val_loss: 0.0119\n",
            "Epoch 33/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0154 - val_loss: 0.0113\n",
            "Epoch 34/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0155 - val_loss: 0.0068\n",
            "Epoch 35/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0151 - val_loss: 0.0095\n",
            "Epoch 36/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0154 - val_loss: 0.0156\n",
            "Epoch 37/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0150 - val_loss: 0.0171\n",
            "Epoch 38/200\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.0150 - val_loss: 0.0076\n",
            "Epoch 39/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0147 - val_loss: 0.0141\n",
            "Epoch 40/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0146 - val_loss: 0.0061\n",
            "Epoch 41/200\n",
            "200/200 [==============================] - 14s 72ms/step - loss: 0.0145 - val_loss: 0.0264\n",
            "Epoch 42/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0145 - val_loss: 0.0174\n",
            "Epoch 43/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0141 - val_loss: 0.0186\n",
            "Epoch 44/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0140 - val_loss: 0.0088\n",
            "Epoch 45/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0142 - val_loss: 0.0092\n",
            "Epoch 46/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0138 - val_loss: 0.0055\n",
            "Epoch 47/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0137 - val_loss: 0.0231\n",
            "Epoch 48/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0136 - val_loss: 0.0122\n",
            "Epoch 49/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0139 - val_loss: 0.0121\n",
            "Epoch 50/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0133 - val_loss: 0.0063\n",
            "Epoch 51/200\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.0136 - val_loss: 0.0095\n",
            "Epoch 52/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0133 - val_loss: 0.0172\n",
            "Epoch 53/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0131 - val_loss: 0.0061\n",
            "Epoch 54/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0132 - val_loss: 0.0112\n",
            "Epoch 55/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0129 - val_loss: 0.0192\n",
            "Epoch 56/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0127 - val_loss: 0.0107\n",
            "Epoch 57/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0129 - val_loss: 0.0060\n",
            "Epoch 58/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0126 - val_loss: 0.0064\n",
            "Epoch 59/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0127 - val_loss: 0.0059\n",
            "Epoch 60/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0125 - val_loss: 0.0268\n",
            "Epoch 61/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0127 - val_loss: 0.0063\n",
            "Epoch 62/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0126 - val_loss: 0.0129\n",
            "Epoch 63/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0126 - val_loss: 0.0079\n",
            "Epoch 64/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0124 - val_loss: 0.0173\n",
            "Epoch 65/200\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.0125 - val_loss: 0.0061\n",
            "Epoch 66/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0123 - val_loss: 0.0213\n",
            "Epoch 67/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0123 - val_loss: 0.0084\n",
            "Epoch 68/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0123 - val_loss: 0.0105\n",
            "Epoch 69/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0122 - val_loss: 0.0060\n",
            "Epoch 70/200\n",
            "200/200 [==============================] - 14s 73ms/step - loss: 0.0125 - val_loss: 0.0083\n",
            "Epoch 71/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0128 - val_loss: 0.0089\n",
            "Epoch 72/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0124 - val_loss: 0.0237\n",
            "Epoch 73/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0121 - val_loss: 0.0068\n",
            "Epoch 74/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0122 - val_loss: 0.0089\n",
            "Epoch 75/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0125 - val_loss: 0.0193\n",
            "Epoch 76/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0122 - val_loss: 0.0063\n",
            "Epoch 77/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0120 - val_loss: 0.0058\n",
            "Epoch 78/200\n",
            "200/200 [==============================] - 16s 82ms/step - loss: 0.0120 - val_loss: 0.0056\n",
            "Epoch 79/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0124 - val_loss: 0.0065\n",
            "Epoch 80/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0121 - val_loss: 0.0058\n",
            "Epoch 81/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0122 - val_loss: 0.0073\n",
            "Epoch 82/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0121 - val_loss: 0.0090\n",
            "Epoch 83/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0119 - val_loss: 0.0120\n",
            "Epoch 84/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0119 - val_loss: 0.0061\n",
            "Epoch 85/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0119 - val_loss: 0.0205\n",
            "Epoch 86/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0119 - val_loss: 0.0071\n",
            "Epoch 87/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0119 - val_loss: 0.0077\n",
            "Epoch 88/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0123 - val_loss: 0.0083\n",
            "Epoch 89/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0119 - val_loss: 0.0062\n",
            "Epoch 90/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0118 - val_loss: 0.0105\n",
            "Epoch 91/200\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.0120 - val_loss: 0.0185\n",
            "Epoch 92/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0118 - val_loss: 0.0061\n",
            "Epoch 93/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0119 - val_loss: 0.0197\n",
            "Epoch 94/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0118 - val_loss: 0.0114\n",
            "Epoch 95/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0120 - val_loss: 0.0063\n",
            "Epoch 96/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0118 - val_loss: 0.0060\n",
            "Epoch 97/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0120 - val_loss: 0.0062\n",
            "Epoch 98/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0118 - val_loss: 0.0219\n",
            "Epoch 99/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0121 - val_loss: 0.0057\n",
            "Epoch 100/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0118 - val_loss: 0.0107\n",
            "Epoch 101/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0118 - val_loss: 0.0077\n",
            "Epoch 102/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0117 - val_loss: 0.0117\n",
            "Epoch 103/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0119 - val_loss: 0.0078\n",
            "Epoch 104/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0117 - val_loss: 0.0152\n",
            "Epoch 105/200\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.0118 - val_loss: 0.0084\n",
            "Epoch 106/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0117 - val_loss: 0.0082\n",
            "Epoch 107/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0117 - val_loss: 0.0161\n",
            "Epoch 108/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0117 - val_loss: 0.0115\n",
            "Epoch 109/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0116 - val_loss: 0.0128\n",
            "Epoch 110/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0118 - val_loss: 0.0168\n",
            "Epoch 111/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0115 - val_loss: 0.0073\n",
            "Epoch 112/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0117 - val_loss: 0.0056\n",
            "Epoch 113/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0115 - val_loss: 0.0060\n",
            "Epoch 114/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0117 - val_loss: 0.0056\n",
            "Epoch 115/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0114 - val_loss: 0.0059\n",
            "Epoch 116/200\n",
            "200/200 [==============================] - 15s 73ms/step - loss: 0.0116 - val_loss: 0.0075\n",
            "Epoch 117/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0114 - val_loss: 0.0210\n",
            "Epoch 118/200\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.0116 - val_loss: 0.0058\n",
            "Epoch 119/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0114 - val_loss: 0.0088\n",
            "Epoch 120/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0116 - val_loss: 0.0146\n",
            "Epoch 121/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0113 - val_loss: 0.0130\n",
            "Epoch 122/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0116 - val_loss: 0.0054\n",
            "Epoch 123/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0113 - val_loss: 0.0138\n",
            "Epoch 124/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0112 - val_loss: 0.0078\n",
            "Epoch 125/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0114 - val_loss: 0.0093\n",
            "Epoch 126/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0113 - val_loss: 0.0084\n",
            "Epoch 127/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0113 - val_loss: 0.0072\n",
            "Epoch 128/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0111 - val_loss: 0.0112\n",
            "Epoch 129/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0112 - val_loss: 0.0154\n",
            "Epoch 130/200\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.0114 - val_loss: 0.0068\n",
            "Epoch 131/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0113 - val_loss: 0.0055\n",
            "Epoch 132/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0112 - val_loss: 0.0215\n",
            "Epoch 133/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0114 - val_loss: 0.0055\n",
            "Epoch 134/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0112 - val_loss: 0.0184\n",
            "Epoch 135/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0113 - val_loss: 0.0115\n",
            "Epoch 136/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0112 - val_loss: 0.0189\n",
            "Epoch 137/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0112 - val_loss: 0.0149\n",
            "Epoch 138/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0112 - val_loss: 0.0060\n",
            "Epoch 139/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0111 - val_loss: 0.0121\n",
            "Epoch 140/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0111 - val_loss: 0.0156\n",
            "Epoch 141/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0112 - val_loss: 0.0066\n",
            "Epoch 142/200\n",
            "200/200 [==============================] - 16s 83ms/step - loss: 0.0111 - val_loss: 0.0126\n",
            "Epoch 143/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0109 - val_loss: 0.0095\n",
            "Epoch 144/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0110 - val_loss: 0.0076\n",
            "Epoch 145/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0111 - val_loss: 0.0058\n",
            "Epoch 146/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0111 - val_loss: 0.0080\n",
            "Epoch 147/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0111 - val_loss: 0.0075\n",
            "Epoch 148/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0110 - val_loss: 0.0057\n",
            "Epoch 149/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0110 - val_loss: 0.0095\n",
            "Epoch 150/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0111 - val_loss: 0.0085\n",
            "Epoch 151/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0109 - val_loss: 0.0127\n",
            "Epoch 152/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0111 - val_loss: 0.0058\n",
            "Epoch 153/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0110 - val_loss: 0.0081\n",
            "Epoch 154/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0110 - val_loss: 0.0102\n",
            "Epoch 155/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0110 - val_loss: 0.0057\n",
            "Epoch 156/200\n",
            "200/200 [==============================] - 17s 85ms/step - loss: 0.0109 - val_loss: 0.0108\n",
            "Epoch 157/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0109 - val_loss: 0.0096\n",
            "Epoch 158/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0108 - val_loss: 0.0110\n",
            "Epoch 159/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0110 - val_loss: 0.0176\n",
            "Epoch 160/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0110 - val_loss: 0.0066\n",
            "Epoch 161/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0110 - val_loss: 0.0087\n",
            "Epoch 162/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0108 - val_loss: 0.0116\n",
            "Epoch 163/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0111 - val_loss: 0.0098\n",
            "Epoch 164/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0110 - val_loss: 0.0094\n",
            "Epoch 165/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0108 - val_loss: 0.0081\n",
            "Epoch 166/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0110 - val_loss: 0.0064\n",
            "Epoch 167/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0110 - val_loss: 0.0236\n",
            "Epoch 168/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0107 - val_loss: 0.0059\n",
            "Epoch 169/200\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.0109 - val_loss: 0.0086\n",
            "Epoch 170/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0108 - val_loss: 0.0208\n",
            "Epoch 171/200\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.0109 - val_loss: 0.0071\n",
            "Epoch 172/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0109 - val_loss: 0.0071\n",
            "Epoch 173/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0109 - val_loss: 0.0107\n",
            "Epoch 174/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0108 - val_loss: 0.0060\n",
            "Epoch 175/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0109 - val_loss: 0.0069\n",
            "Epoch 176/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0108 - val_loss: 0.0092\n",
            "Epoch 177/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0108 - val_loss: 0.0059\n",
            "Epoch 178/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0108 - val_loss: 0.0173\n",
            "Epoch 179/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0107 - val_loss: 0.0059\n",
            "Epoch 180/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0108 - val_loss: 0.0097\n",
            "Epoch 181/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0105 - val_loss: 0.0135\n",
            "Epoch 182/200\n",
            "200/200 [==============================] - 17s 84ms/step - loss: 0.0106 - val_loss: 0.0069\n",
            "Epoch 183/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0106 - val_loss: 0.0064\n",
            "Epoch 184/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0109 - val_loss: 0.0057\n",
            "Epoch 185/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0106 - val_loss: 0.0063\n",
            "Epoch 186/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0107 - val_loss: 0.0166\n",
            "Epoch 187/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0107 - val_loss: 0.0091\n",
            "Epoch 188/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0107 - val_loss: 0.0087\n",
            "Epoch 189/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0106 - val_loss: 0.0168\n",
            "Epoch 190/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0105 - val_loss: 0.0055\n",
            "Epoch 191/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0105 - val_loss: 0.0103\n",
            "Epoch 192/200\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 0.0108 - val_loss: 0.0140\n",
            "Epoch 193/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0107 - val_loss: 0.0191\n",
            "Epoch 194/200\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 0.0108 - val_loss: 0.0062\n",
            "Epoch 195/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0107 - val_loss: 0.0085\n",
            "Epoch 196/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0104 - val_loss: 0.0058\n",
            "Epoch 197/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0107 - val_loss: 0.0129\n",
            "Epoch 198/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0107 - val_loss: 0.0057\n",
            "Epoch 199/200\n",
            "200/200 [==============================] - 15s 75ms/step - loss: 0.0105 - val_loss: 0.0125\n",
            "Epoch 200/200\n",
            "200/200 [==============================] - 15s 74ms/step - loss: 0.0104 - val_loss: 0.0076\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(layers.LSTM(120,\n",
        "  activation='sigmoid',\n",
        "  #dropout=0.1,\n",
        "  #recurrent_dropout=0.1,\n",
        "  input_shape=(None, float_data.shape[-1])))\n",
        "model.add(layers.Dense(160,\n",
        "  activation='sigmoid',))\n",
        "model.add(layers.Dense(1,\n",
        "  activation='sigmoid'))\n",
        "model.compile(optimizer= tf.keras.optimizers.RMSprop(0.01), loss='mae')\n",
        "history = model.fit(train_gen,\n",
        "  steps_per_epoch=200,\n",
        "  epochs=200,\n",
        "  validation_data=val_gen,\n",
        "  validation_steps=val_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_zXegCCEWzZ",
        "outputId": "e3e25b0f-542d-4be1-fe6f-c697279dcf25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "527/527 [==============================] - 9s 17ms/step - loss: 0.0111\n"
          ]
        }
      ],
      "source": [
        "eval = model.evaluate(test_gen, steps = test_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do a tuner of architecture above, 110-130, 150-170 and dropout, with step of 5"
      ],
      "metadata": {
        "id": "38OKUJHFYOCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model same, but with dropout and recurrent dropout 0.1\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yjO7MqZTlMY3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TmUE1wKPM-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b68f136d-3414-4471-df30-8b8501a08e8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "200/200 [==============================] - 22s 93ms/step - loss: 0.2084 - val_loss: 0.2017\n",
            "Epoch 2/200\n",
            "200/200 [==============================] - 18s 92ms/step - loss: 0.0775 - val_loss: 0.0804\n",
            "Epoch 3/200\n",
            "200/200 [==============================] - 18s 90ms/step - loss: 0.0611 - val_loss: 0.0450\n",
            "Epoch 4/200\n",
            "200/200 [==============================] - 18s 92ms/step - loss: 0.0529 - val_loss: 0.0238\n",
            "Epoch 5/200\n",
            "200/200 [==============================] - 19s 93ms/step - loss: 0.0478 - val_loss: 0.0629\n",
            "Epoch 6/200\n",
            "200/200 [==============================] - 18s 92ms/step - loss: 0.0462 - val_loss: 0.0333\n",
            "Epoch 7/200\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.0428 - val_loss: 0.0220\n",
            "Epoch 8/200\n",
            "200/200 [==============================] - 19s 98ms/step - loss: 0.0420 - val_loss: 0.0426\n",
            "Epoch 9/200\n",
            "200/200 [==============================] - 20s 98ms/step - loss: 0.0400 - val_loss: 0.0541\n",
            "Epoch 10/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0397 - val_loss: 0.0415\n",
            "Epoch 11/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0384 - val_loss: 0.0268\n",
            "Epoch 12/200\n",
            "200/200 [==============================] - 18s 92ms/step - loss: 0.0387 - val_loss: 0.0678\n",
            "Epoch 13/200\n",
            "200/200 [==============================] - 19s 93ms/step - loss: 0.0376 - val_loss: 0.0255\n",
            "Epoch 14/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0368 - val_loss: 0.0406\n",
            "Epoch 15/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0365 - val_loss: 0.0164\n",
            "Epoch 16/200\n",
            "200/200 [==============================] - 20s 98ms/step - loss: 0.0358 - val_loss: 0.0598\n",
            "Epoch 17/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0358 - val_loss: 0.0619\n",
            "Epoch 18/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0350 - val_loss: 0.0674\n",
            "Epoch 19/200\n",
            "200/200 [==============================] - 19s 93ms/step - loss: 0.0349 - val_loss: 0.0517\n",
            "Epoch 20/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0346 - val_loss: 0.0321\n",
            "Epoch 21/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0344 - val_loss: 0.0170\n",
            "Epoch 22/200\n",
            "200/200 [==============================] - 21s 104ms/step - loss: 0.0336 - val_loss: 0.0257\n",
            "Epoch 23/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0336 - val_loss: 0.0333\n",
            "Epoch 24/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0330 - val_loss: 0.0421\n",
            "Epoch 25/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0333 - val_loss: 0.0292\n",
            "Epoch 26/200\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0325 - val_loss: 0.0155\n",
            "Epoch 27/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0325 - val_loss: 0.0484\n",
            "Epoch 28/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0318 - val_loss: 0.0280\n",
            "Epoch 29/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0322 - val_loss: 0.0470\n",
            "Epoch 30/200\n",
            "200/200 [==============================] - 20s 99ms/step - loss: 0.0312 - val_loss: 0.0209\n",
            "Epoch 31/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0314 - val_loss: 0.0515\n",
            "Epoch 32/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0309 - val_loss: 0.0269\n",
            "Epoch 33/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0311 - val_loss: 0.0453\n",
            "Epoch 34/200\n",
            "200/200 [==============================] - 19s 93ms/step - loss: 0.0304 - val_loss: 0.0292\n",
            "Epoch 35/200\n",
            "200/200 [==============================] - 19s 93ms/step - loss: 0.0300 - val_loss: 0.0475\n",
            "Epoch 36/200\n",
            "200/200 [==============================] - 20s 101ms/step - loss: 0.0308 - val_loss: 0.0716\n",
            "Epoch 37/200\n",
            "200/200 [==============================] - 19s 93ms/step - loss: 0.0302 - val_loss: 0.0587\n",
            "Epoch 38/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0298 - val_loss: 0.0659\n",
            "Epoch 39/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0293 - val_loss: 0.0622\n",
            "Epoch 40/200\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.0296 - val_loss: 0.0266\n",
            "Epoch 41/200\n",
            "200/200 [==============================] - 18s 92ms/step - loss: 0.0291 - val_loss: 0.0424\n",
            "Epoch 42/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0291 - val_loss: 0.0384\n",
            "Epoch 43/200\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.0283 - val_loss: 0.0530\n",
            "Epoch 44/200\n",
            "200/200 [==============================] - 19s 93ms/step - loss: 0.0285 - val_loss: 0.0486\n",
            "Epoch 45/200\n",
            "200/200 [==============================] - 18s 92ms/step - loss: 0.0283 - val_loss: 0.0385\n",
            "Epoch 46/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0286 - val_loss: 0.0517\n",
            "Epoch 47/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0278 - val_loss: 0.0143\n",
            "Epoch 48/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0277 - val_loss: 0.0565\n",
            "Epoch 49/200\n",
            "200/200 [==============================] - 21s 107ms/step - loss: 0.0274 - val_loss: 0.0374\n",
            "Epoch 50/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0275 - val_loss: 0.0632\n",
            "Epoch 51/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0271 - val_loss: 0.0122\n",
            "Epoch 52/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0272 - val_loss: 0.0623\n",
            "Epoch 53/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0268 - val_loss: 0.0502\n",
            "Epoch 54/200\n",
            "200/200 [==============================] - 19s 93ms/step - loss: 0.0268 - val_loss: 0.0681\n",
            "Epoch 55/200\n",
            "200/200 [==============================] - 19s 93ms/step - loss: 0.0266 - val_loss: 0.0801\n",
            "Epoch 56/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0262 - val_loss: 0.0749\n",
            "Epoch 57/200\n",
            "200/200 [==============================] - 18s 92ms/step - loss: 0.0263 - val_loss: 0.0822\n",
            "Epoch 58/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0259 - val_loss: 0.0761\n",
            "Epoch 59/200\n",
            "200/200 [==============================] - 18s 92ms/step - loss: 0.0259 - val_loss: 0.0521\n",
            "Epoch 60/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0251 - val_loss: 0.0511\n",
            "Epoch 61/200\n",
            "200/200 [==============================] - 19s 93ms/step - loss: 0.0247 - val_loss: 0.0617\n",
            "Epoch 62/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0247 - val_loss: 0.0623\n",
            "Epoch 63/200\n",
            "200/200 [==============================] - 21s 103ms/step - loss: 0.0244 - val_loss: 0.0565\n",
            "Epoch 64/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0243 - val_loss: 0.0299\n",
            "Epoch 65/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0244 - val_loss: 0.0683\n",
            "Epoch 66/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0236 - val_loss: 0.0411\n",
            "Epoch 67/200\n",
            "200/200 [==============================] - 18s 92ms/step - loss: 0.0237 - val_loss: 0.0622\n",
            "Epoch 68/200\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0234 - val_loss: 0.0566\n",
            "Epoch 69/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0233 - val_loss: 0.0637\n",
            "Epoch 70/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0227 - val_loss: 0.0223\n",
            "Epoch 71/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0228 - val_loss: 0.0698\n",
            "Epoch 72/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0225 - val_loss: 0.0536\n",
            "Epoch 73/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0221 - val_loss: 0.0726\n",
            "Epoch 74/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0221 - val_loss: 0.0860\n",
            "Epoch 75/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0217 - val_loss: 0.0759\n",
            "Epoch 76/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0215 - val_loss: 0.0790\n",
            "Epoch 77/200\n",
            "200/200 [==============================] - 20s 102ms/step - loss: 0.0211 - val_loss: 0.0725\n",
            "Epoch 78/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0212 - val_loss: 0.0554\n",
            "Epoch 79/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0209 - val_loss: 0.0611\n",
            "Epoch 80/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0207 - val_loss: 0.0585\n",
            "Epoch 81/200\n",
            "200/200 [==============================] - 19s 93ms/step - loss: 0.0208 - val_loss: 0.0743\n",
            "Epoch 82/200\n",
            "200/200 [==============================] - 18s 91ms/step - loss: 0.0204 - val_loss: 0.0598\n",
            "Epoch 83/200\n",
            "200/200 [==============================] - 19s 93ms/step - loss: 0.0201 - val_loss: 0.0472\n",
            "Epoch 84/200\n",
            "200/200 [==============================] - 19s 93ms/step - loss: 0.0204 - val_loss: 0.0713\n",
            "Epoch 85/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0200 - val_loss: 0.0661\n",
            "Epoch 86/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0201 - val_loss: 0.0600\n",
            "Epoch 87/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0197 - val_loss: 0.0339\n",
            "Epoch 88/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0198 - val_loss: 0.0731\n",
            "Epoch 89/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0194 - val_loss: 0.0486\n",
            "Epoch 90/200\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0195 - val_loss: 0.0668\n",
            "Epoch 91/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0193 - val_loss: 0.0672\n",
            "Epoch 92/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0193 - val_loss: 0.0786\n",
            "Epoch 93/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0191 - val_loss: 0.0901\n",
            "Epoch 94/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0190 - val_loss: 0.0784\n",
            "Epoch 95/200\n",
            "200/200 [==============================] - 19s 93ms/step - loss: 0.0188 - val_loss: 0.0858\n",
            "Epoch 96/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0189 - val_loss: 0.0789\n",
            "Epoch 97/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0184 - val_loss: 0.0639\n",
            "Epoch 98/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0186 - val_loss: 0.0543\n",
            "Epoch 99/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0185 - val_loss: 0.0654\n",
            "Epoch 100/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0187 - val_loss: 0.0778\n",
            "Epoch 101/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0184 - val_loss: 0.0638\n",
            "Epoch 102/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0182 - val_loss: 0.0488\n",
            "Epoch 103/200\n",
            "200/200 [==============================] - 21s 106ms/step - loss: 0.0184 - val_loss: 0.0609\n",
            "Epoch 104/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0184 - val_loss: 0.0593\n",
            "Epoch 105/200\n",
            "200/200 [==============================] - 20s 99ms/step - loss: 0.0182 - val_loss: 0.0691\n",
            "Epoch 106/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0181 - val_loss: 0.0633\n",
            "Epoch 107/200\n",
            "200/200 [==============================] - 19s 98ms/step - loss: 0.0181 - val_loss: 0.0764\n",
            "Epoch 108/200\n",
            "200/200 [==============================] - 20s 99ms/step - loss: 0.0179 - val_loss: 0.0417\n",
            "Epoch 109/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0181 - val_loss: 0.0745\n",
            "Epoch 110/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0177 - val_loss: 0.0532\n",
            "Epoch 111/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0181 - val_loss: 0.0765\n",
            "Epoch 112/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0178 - val_loss: 0.0910\n",
            "Epoch 113/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0178 - val_loss: 0.0754\n",
            "Epoch 114/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0176 - val_loss: 0.0822\n",
            "Epoch 115/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0177 - val_loss: 0.0722\n",
            "Epoch 116/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0178 - val_loss: 0.0676\n",
            "Epoch 117/200\n",
            "200/200 [==============================] - 21s 106ms/step - loss: 0.0175 - val_loss: 0.0615\n",
            "Epoch 118/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0176 - val_loss: 0.0656\n",
            "Epoch 119/200\n",
            "200/200 [==============================] - 20s 98ms/step - loss: 0.0178 - val_loss: 0.0790\n",
            "Epoch 120/200\n",
            "200/200 [==============================] - 20s 99ms/step - loss: 0.0177 - val_loss: 0.0719\n",
            "Epoch 121/200\n",
            "200/200 [==============================] - 20s 98ms/step - loss: 0.0175 - val_loss: 0.0507\n",
            "Epoch 122/200\n",
            "200/200 [==============================] - 20s 98ms/step - loss: 0.0178 - val_loss: 0.0722\n",
            "Epoch 123/200\n",
            "200/200 [==============================] - 20s 99ms/step - loss: 0.0174 - val_loss: 0.0768\n",
            "Epoch 124/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0176 - val_loss: 0.0686\n",
            "Epoch 125/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0173 - val_loss: 0.0421\n",
            "Epoch 126/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0175 - val_loss: 0.0719\n",
            "Epoch 127/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0173 - val_loss: 0.0609\n",
            "Epoch 128/200\n",
            "200/200 [==============================] - 20s 98ms/step - loss: 0.0174 - val_loss: 0.0653\n",
            "Epoch 129/200\n",
            "200/200 [==============================] - 20s 99ms/step - loss: 0.0173 - val_loss: 0.0717\n",
            "Epoch 130/200\n",
            "200/200 [==============================] - 22s 109ms/step - loss: 0.0170 - val_loss: 0.0751\n",
            "Epoch 131/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0172 - val_loss: 0.0784\n",
            "Epoch 132/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0172 - val_loss: 0.0792\n",
            "Epoch 133/200\n",
            "200/200 [==============================] - 20s 98ms/step - loss: 0.0173 - val_loss: 0.0688\n",
            "Epoch 134/200\n",
            "200/200 [==============================] - 20s 98ms/step - loss: 0.0171 - val_loss: 0.0768\n",
            "Epoch 135/200\n",
            "200/200 [==============================] - 20s 99ms/step - loss: 0.0173 - val_loss: 0.0749\n",
            "Epoch 136/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0170 - val_loss: 0.0690\n",
            "Epoch 137/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0171 - val_loss: 0.0770\n",
            "Epoch 138/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0169 - val_loss: 0.0742\n",
            "Epoch 139/200\n",
            "200/200 [==============================] - 19s 98ms/step - loss: 0.0170 - val_loss: 0.0689\n",
            "Epoch 140/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0168 - val_loss: 0.0509\n",
            "Epoch 141/200\n",
            "200/200 [==============================] - 20s 98ms/step - loss: 0.0171 - val_loss: 0.0744\n",
            "Epoch 142/200\n",
            "200/200 [==============================] - 21s 106ms/step - loss: 0.0169 - val_loss: 0.0556\n",
            "Epoch 143/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0170 - val_loss: 0.0734\n",
            "Epoch 144/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0167 - val_loss: 0.0411\n",
            "Epoch 145/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0170 - val_loss: 0.0763\n",
            "Epoch 146/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0166 - val_loss: 0.0566\n",
            "Epoch 147/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0169 - val_loss: 0.0754\n",
            "Epoch 148/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0168 - val_loss: 0.0693\n",
            "Epoch 149/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0169 - val_loss: 0.0767\n",
            "Epoch 150/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0167 - val_loss: 0.0850\n",
            "Epoch 151/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0167 - val_loss: 0.0817\n",
            "Epoch 152/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0166 - val_loss: 0.0848\n",
            "Epoch 153/200\n",
            "200/200 [==============================] - 19s 94ms/step - loss: 0.0166 - val_loss: 0.0824\n",
            "Epoch 154/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0167 - val_loss: 0.0751\n",
            "Epoch 155/200\n",
            "200/200 [==============================] - 21s 103ms/step - loss: 0.0167 - val_loss: 0.0686\n",
            "Epoch 156/200\n",
            "200/200 [==============================] - 19s 93ms/step - loss: 0.0166 - val_loss: 0.0645\n",
            "Epoch 157/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0165 - val_loss: 0.0611\n",
            "Epoch 158/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0167 - val_loss: 0.0666\n",
            "Epoch 159/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0165 - val_loss: 0.0681\n",
            "Epoch 160/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0165 - val_loss: 0.0728\n",
            "Epoch 161/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0164 - val_loss: 0.0670\n",
            "Epoch 162/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0166 - val_loss: 0.0683\n",
            "Epoch 163/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0164 - val_loss: 0.0426\n",
            "Epoch 164/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0164 - val_loss: 0.0730\n",
            "Epoch 165/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0163 - val_loss: 0.0450\n",
            "Epoch 166/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0164 - val_loss: 0.0644\n",
            "Epoch 167/200\n",
            "200/200 [==============================] - 20s 99ms/step - loss: 0.0165 - val_loss: 0.0797\n",
            "Epoch 168/200\n",
            "200/200 [==============================] - 20s 98ms/step - loss: 0.0164 - val_loss: 0.0717\n",
            "Epoch 169/200\n",
            "200/200 [==============================] - 21s 103ms/step - loss: 0.0163 - val_loss: 0.0827\n",
            "Epoch 170/200\n",
            "200/200 [==============================] - 20s 98ms/step - loss: 0.0164 - val_loss: 0.0733\n",
            "Epoch 171/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0162 - val_loss: 0.0892\n",
            "Epoch 172/200\n",
            "200/200 [==============================] - 20s 98ms/step - loss: 0.0164 - val_loss: 0.0747\n",
            "Epoch 173/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0161 - val_loss: 0.0726\n",
            "Epoch 174/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0163 - val_loss: 0.0811\n",
            "Epoch 175/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0162 - val_loss: 0.0717\n",
            "Epoch 176/200\n",
            "200/200 [==============================] - 20s 98ms/step - loss: 0.0162 - val_loss: 0.0681\n",
            "Epoch 177/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0163 - val_loss: 0.0700\n",
            "Epoch 178/200\n",
            "200/200 [==============================] - 20s 100ms/step - loss: 0.0161 - val_loss: 0.0525\n",
            "Epoch 179/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0162 - val_loss: 0.0715\n",
            "Epoch 180/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0162 - val_loss: 0.0463\n",
            "Epoch 181/200\n",
            "200/200 [==============================] - 21s 106ms/step - loss: 0.0162 - val_loss: 0.0679\n",
            "Epoch 182/200\n",
            "200/200 [==============================] - 20s 98ms/step - loss: 0.0161 - val_loss: 0.0455\n",
            "Epoch 183/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0161 - val_loss: 0.0733\n",
            "Epoch 184/200\n",
            "200/200 [==============================] - 20s 98ms/step - loss: 0.0161 - val_loss: 0.0530\n",
            "Epoch 185/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0161 - val_loss: 0.0718\n",
            "Epoch 186/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0162 - val_loss: 0.0678\n",
            "Epoch 187/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0161 - val_loss: 0.0690\n",
            "Epoch 188/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0161 - val_loss: 0.0752\n",
            "Epoch 189/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0160 - val_loss: 0.0677\n",
            "Epoch 190/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0161 - val_loss: 0.0699\n",
            "Epoch 191/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0160 - val_loss: 0.0716\n",
            "Epoch 192/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0160 - val_loss: 0.0636\n",
            "Epoch 193/200\n",
            "200/200 [==============================] - 19s 95ms/step - loss: 0.0162 - val_loss: 0.0679\n",
            "Epoch 194/200\n",
            "200/200 [==============================] - 21s 104ms/step - loss: 0.0160 - val_loss: 0.0757\n",
            "Epoch 195/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0160 - val_loss: 0.0732\n",
            "Epoch 196/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0161 - val_loss: 0.0698\n",
            "Epoch 197/200\n",
            "200/200 [==============================] - 19s 96ms/step - loss: 0.0159 - val_loss: 0.0567\n",
            "Epoch 198/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0161 - val_loss: 0.0781\n",
            "Epoch 199/200\n",
            "200/200 [==============================] - 20s 98ms/step - loss: 0.0159 - val_loss: 0.0705\n",
            "Epoch 200/200\n",
            "200/200 [==============================] - 19s 97ms/step - loss: 0.0159 - val_loss: 0.0657\n"
          ]
        }
      ],
      "source": [
        "model1 = tf.keras.models.Sequential()\n",
        "model1.add(layers.LSTM(120,\n",
        "  activation='sigmoid',\n",
        "  dropout=0.1,\n",
        "  recurrent_dropout=0.1,\n",
        "  input_shape=(None, float_data.shape[-1])))\n",
        "model1.add(layers.Dense(160,\n",
        "  activation='sigmoid',))\n",
        "model1.add(layers.Dense(1,\n",
        "  activation='sigmoid'))\n",
        "model1.compile(optimizer= tf.keras.optimizers.RMSprop(0.01), loss='mae')\n",
        "history1 = model1.fit(train_gen,\n",
        "  steps_per_epoch=200,\n",
        "  epochs=200,\n",
        "  validation_data=val_gen,\n",
        "  validation_steps=val_steps)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval1 = model1.evaluate(test_gen, steps = test_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7uTxtKF0K-a",
        "outputId": "0725c1e3-99aa-4f91-848e-8d54d53b41e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "527/527 [==============================] - 12s 23ms/step - loss: 0.0681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del model2"
      ],
      "metadata": {
        "id": "xSMVmUH5irx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "without steps per epoch- infinity\n",
        "120-160 without dropout 0.017\n",
        "120-5 dropout 0.15"
      ],
      "metadata": {
        "id": "EkWBHx89ijRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.models.Sequential()\n",
        "model2.add(layers.LSTM(120,\n",
        "  activation='sigmoid',\n",
        "  dropout=0.15,\n",
        "  recurrent_dropout=0.1,\n",
        "  input_shape=(None, float_data.shape[-1])))\n",
        "model2.add(layers.Dense(5,\n",
        "  activation='sigmoid',))\n",
        "model2.add(layers.Dense(1,\n",
        "  activation='sigmoid'))\n",
        "model2.compile(optimizer= tf.keras.optimizers.RMSprop(0.01), loss='mae')\n",
        "history2 = model2.fit(train_gen,\n",
        "  steps_per_epoch=50,\n",
        "  epochs=200,\n",
        "  validation_data=val_gen,\n",
        "  validation_steps=val_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTm2ga9m0yYG",
        "outputId": "06ad91df-fbeb-45a6-f488-7612d26167cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "50/50 [==============================] - 9s 144ms/step - loss: 0.1801 - val_loss: 0.0402\n",
            "Epoch 2/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.1337 - val_loss: 0.2722\n",
            "Epoch 3/200\n",
            "50/50 [==============================] - 7s 138ms/step - loss: 0.0901 - val_loss: 0.0824\n",
            "Epoch 4/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0673 - val_loss: 0.0667\n",
            "Epoch 5/200\n",
            "50/50 [==============================] - 7s 136ms/step - loss: 0.0683 - val_loss: 0.0436\n",
            "Epoch 6/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0603 - val_loss: 0.0552\n",
            "Epoch 7/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0584 - val_loss: 0.0269\n",
            "Epoch 8/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0613 - val_loss: 0.1071\n",
            "Epoch 9/200\n",
            "50/50 [==============================] - 7s 138ms/step - loss: 0.0548 - val_loss: 0.0437\n",
            "Epoch 10/200\n",
            "50/50 [==============================] - 8s 155ms/step - loss: 0.0552 - val_loss: 0.0596\n",
            "Epoch 11/200\n",
            "50/50 [==============================] - 7s 136ms/step - loss: 0.0539 - val_loss: 0.0418\n",
            "Epoch 12/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0501 - val_loss: 0.0318\n",
            "Epoch 13/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0507 - val_loss: 0.0464\n",
            "Epoch 14/200\n",
            "50/50 [==============================] - 7s 145ms/step - loss: 0.0492 - val_loss: 0.0336\n",
            "Epoch 15/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0472 - val_loss: 0.0344\n",
            "Epoch 16/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0486 - val_loss: 0.0567\n",
            "Epoch 17/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0454 - val_loss: 0.0492\n",
            "Epoch 18/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0442 - val_loss: 0.0338\n",
            "Epoch 19/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0460 - val_loss: 0.0618\n",
            "Epoch 20/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0427 - val_loss: 0.0419\n",
            "Epoch 21/200\n",
            "50/50 [==============================] - 7s 135ms/step - loss: 0.0426 - val_loss: 0.0889\n",
            "Epoch 22/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0429 - val_loss: 0.0396\n",
            "Epoch 23/200\n",
            "50/50 [==============================] - 7s 137ms/step - loss: 0.0411 - val_loss: 0.0584\n",
            "Epoch 24/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0427 - val_loss: 0.0541\n",
            "Epoch 25/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0409 - val_loss: 0.0371\n",
            "Epoch 26/200\n",
            "50/50 [==============================] - 7s 138ms/step - loss: 0.0406 - val_loss: 0.0178\n",
            "Epoch 27/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0408 - val_loss: 0.0356\n",
            "Epoch 28/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0398 - val_loss: 0.0221\n",
            "Epoch 29/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0397 - val_loss: 0.0683\n",
            "Epoch 30/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0393 - val_loss: 0.0367\n",
            "Epoch 31/200\n",
            "50/50 [==============================] - 7s 146ms/step - loss: 0.0385 - val_loss: 0.0222\n",
            "Epoch 32/200\n",
            "50/50 [==============================] - 7s 138ms/step - loss: 0.0394 - val_loss: 0.0629\n",
            "Epoch 33/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0381 - val_loss: 0.0258\n",
            "Epoch 34/200\n",
            "50/50 [==============================] - 7s 144ms/step - loss: 0.0375 - val_loss: 0.0221\n",
            "Epoch 35/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0389 - val_loss: 0.0765\n",
            "Epoch 36/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0371 - val_loss: 0.0189\n",
            "Epoch 37/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0353 - val_loss: 0.0402\n",
            "Epoch 38/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0385 - val_loss: 0.0616\n",
            "Epoch 39/200\n",
            "50/50 [==============================] - 7s 144ms/step - loss: 0.0353 - val_loss: 0.0320\n",
            "Epoch 40/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0367 - val_loss: 0.1104\n",
            "Epoch 41/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0371 - val_loss: 0.0244\n",
            "Epoch 42/200\n",
            "50/50 [==============================] - 9s 180ms/step - loss: 0.0355 - val_loss: 0.0225\n",
            "Epoch 43/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0366 - val_loss: 0.0563\n",
            "Epoch 44/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0367 - val_loss: 0.0443\n",
            "Epoch 45/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0346 - val_loss: 0.0198\n",
            "Epoch 46/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0367 - val_loss: 0.0717\n",
            "Epoch 47/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0344 - val_loss: 0.0152\n",
            "Epoch 48/200\n",
            "50/50 [==============================] - 7s 145ms/step - loss: 0.0338 - val_loss: 0.0900\n",
            "Epoch 49/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0380 - val_loss: 0.0375\n",
            "Epoch 50/200\n",
            "50/50 [==============================] - 7s 138ms/step - loss: 0.0340 - val_loss: 0.0247\n",
            "Epoch 51/200\n",
            "50/50 [==============================] - 7s 144ms/step - loss: 0.0352 - val_loss: 0.0726\n",
            "Epoch 52/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0350 - val_loss: 0.0222\n",
            "Epoch 53/200\n",
            "50/50 [==============================] - 7s 144ms/step - loss: 0.0330 - val_loss: 0.0146\n",
            "Epoch 54/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0361 - val_loss: 0.0717\n",
            "Epoch 55/200\n",
            "50/50 [==============================] - 7s 145ms/step - loss: 0.0337 - val_loss: 0.0298\n",
            "Epoch 56/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0349 - val_loss: 0.0427\n",
            "Epoch 57/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0355 - val_loss: 0.0780\n",
            "Epoch 58/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0336 - val_loss: 0.0250\n",
            "Epoch 59/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0357 - val_loss: 0.0845\n",
            "Epoch 60/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0342 - val_loss: 0.0313\n",
            "Epoch 61/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0326 - val_loss: 0.0166\n",
            "Epoch 62/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0366 - val_loss: 0.0609\n",
            "Epoch 63/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0339 - val_loss: 0.0397\n",
            "Epoch 64/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0316 - val_loss: 0.0284\n",
            "Epoch 65/200\n",
            "50/50 [==============================] - 7s 144ms/step - loss: 0.0382 - val_loss: 0.0517\n",
            "Epoch 66/200\n",
            "50/50 [==============================] - 7s 144ms/step - loss: 0.0319 - val_loss: 0.0311\n",
            "Epoch 67/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0326 - val_loss: 0.0960\n",
            "Epoch 68/200\n",
            "50/50 [==============================] - 7s 137ms/step - loss: 0.0345 - val_loss: 0.0908\n",
            "Epoch 69/200\n",
            "50/50 [==============================] - 7s 136ms/step - loss: 0.0319 - val_loss: 0.0220\n",
            "Epoch 70/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0348 - val_loss: 0.1074\n",
            "Epoch 71/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0334 - val_loss: 0.0225\n",
            "Epoch 72/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0330 - val_loss: 0.0166\n",
            "Epoch 73/200\n",
            "50/50 [==============================] - 7s 145ms/step - loss: 0.0331 - val_loss: 0.0787\n",
            "Epoch 74/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0329 - val_loss: 0.0445\n",
            "Epoch 75/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0321 - val_loss: 0.0513\n",
            "Epoch 76/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0403 - val_loss: 0.0891\n",
            "Epoch 77/200\n",
            "50/50 [==============================] - 7s 144ms/step - loss: 0.0317 - val_loss: 0.0179\n",
            "Epoch 78/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0323 - val_loss: 0.0814\n",
            "Epoch 79/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0355 - val_loss: 0.0395\n",
            "Epoch 80/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0314 - val_loss: 0.0165\n",
            "Epoch 81/200\n",
            "50/50 [==============================] - 7s 144ms/step - loss: 0.0338 - val_loss: 0.0784\n",
            "Epoch 82/200\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 0.0320 - val_loss: 0.0715\n",
            "Epoch 83/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0326 - val_loss: 0.0500\n",
            "Epoch 84/200\n",
            "50/50 [==============================] - 7s 138ms/step - loss: 0.0382 - val_loss: 0.0651\n",
            "Epoch 85/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0309 - val_loss: 0.0426\n",
            "Epoch 86/200\n",
            "50/50 [==============================] - 7s 144ms/step - loss: 0.0305 - val_loss: 0.0877\n",
            "Epoch 87/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0328 - val_loss: 0.0535\n",
            "Epoch 88/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0338 - val_loss: 0.0336\n",
            "Epoch 89/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0327 - val_loss: 0.0941\n",
            "Epoch 90/200\n",
            "50/50 [==============================] - 7s 144ms/step - loss: 0.0339 - val_loss: 0.0302\n",
            "Epoch 91/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0306 - val_loss: 0.0292\n",
            "Epoch 92/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0340 - val_loss: 0.0828\n",
            "Epoch 93/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0303 - val_loss: 0.1210\n",
            "Epoch 94/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0318 - val_loss: 0.0505\n",
            "Epoch 95/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0328 - val_loss: 0.0637\n",
            "Epoch 96/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0319 - val_loss: 0.0151\n",
            "Epoch 97/200\n",
            "50/50 [==============================] - 7s 138ms/step - loss: 0.0313 - val_loss: 0.0965\n",
            "Epoch 98/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0326 - val_loss: 0.0475\n",
            "Epoch 99/200\n",
            "50/50 [==============================] - 7s 137ms/step - loss: 0.0303 - val_loss: 0.0261\n",
            "Epoch 100/200\n",
            "50/50 [==============================] - 7s 138ms/step - loss: 0.0325 - val_loss: 0.0811\n",
            "Epoch 101/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0295 - val_loss: 0.0674\n",
            "Epoch 102/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0317 - val_loss: 0.0650\n",
            "Epoch 103/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0339 - val_loss: 0.0636\n",
            "Epoch 104/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0309 - val_loss: 0.0438\n",
            "Epoch 105/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0302 - val_loss: 0.1044\n",
            "Epoch 106/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0318 - val_loss: 0.0449\n",
            "Epoch 107/200\n",
            "50/50 [==============================] - 7s 144ms/step - loss: 0.0292 - val_loss: 0.0466\n",
            "Epoch 108/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0316 - val_loss: 0.0907\n",
            "Epoch 109/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0302 - val_loss: 0.0398\n",
            "Epoch 110/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0307 - val_loss: 0.0221\n",
            "Epoch 111/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0314 - val_loss: 0.0806\n",
            "Epoch 112/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0297 - val_loss: 0.1198\n",
            "Epoch 113/200\n",
            "50/50 [==============================] - 7s 138ms/step - loss: 0.0300 - val_loss: 0.0552\n",
            "Epoch 114/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0311 - val_loss: 0.0707\n",
            "Epoch 115/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0288 - val_loss: 0.0154\n",
            "Epoch 116/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0300 - val_loss: 0.1100\n",
            "Epoch 117/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0292 - val_loss: 0.0499\n",
            "Epoch 118/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0285 - val_loss: 0.0324\n",
            "Epoch 119/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0298 - val_loss: 0.0850\n",
            "Epoch 120/200\n",
            "50/50 [==============================] - 7s 144ms/step - loss: 0.0285 - val_loss: 0.0974\n",
            "Epoch 121/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0282 - val_loss: 0.0473\n",
            "Epoch 122/200\n",
            "50/50 [==============================] - 7s 144ms/step - loss: 0.0302 - val_loss: 0.0746\n",
            "Epoch 123/200\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 0.0287 - val_loss: 0.0405\n",
            "Epoch 124/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0282 - val_loss: 0.1012\n",
            "Epoch 125/200\n",
            "50/50 [==============================] - 7s 137ms/step - loss: 0.0286 - val_loss: 0.0395\n",
            "Epoch 126/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0272 - val_loss: 0.0616\n",
            "Epoch 127/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0289 - val_loss: 0.1144\n",
            "Epoch 128/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0281 - val_loss: 0.0508\n",
            "Epoch 129/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0271 - val_loss: 0.0262\n",
            "Epoch 130/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0282 - val_loss: 0.0894\n",
            "Epoch 131/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0265 - val_loss: 0.1271\n",
            "Epoch 132/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0278 - val_loss: 0.0688\n",
            "Epoch 133/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0278 - val_loss: 0.0841\n",
            "Epoch 134/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0267 - val_loss: 0.0242\n",
            "Epoch 135/200\n",
            "50/50 [==============================] - 7s 145ms/step - loss: 0.0273 - val_loss: 0.1095\n",
            "Epoch 136/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0268 - val_loss: 0.0668\n",
            "Epoch 137/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0267 - val_loss: 0.0528\n",
            "Epoch 138/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0268 - val_loss: 0.0997\n",
            "Epoch 139/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0268 - val_loss: 0.0999\n",
            "Epoch 140/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0267 - val_loss: 0.0666\n",
            "Epoch 141/200\n",
            "50/50 [==============================] - 7s 146ms/step - loss: 0.0276 - val_loss: 0.0922\n",
            "Epoch 142/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0262 - val_loss: 0.0896\n",
            "Epoch 143/200\n",
            "50/50 [==============================] - 7s 137ms/step - loss: 0.0262 - val_loss: 0.1127\n",
            "Epoch 144/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0261 - val_loss: 0.0762\n",
            "Epoch 145/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0262 - val_loss: 0.0687\n",
            "Epoch 146/200\n",
            "50/50 [==============================] - 7s 146ms/step - loss: 0.0265 - val_loss: 0.1028\n",
            "Epoch 147/200\n",
            "50/50 [==============================] - 7s 149ms/step - loss: 0.0261 - val_loss: 0.0747\n",
            "Epoch 148/200\n",
            "50/50 [==============================] - 7s 144ms/step - loss: 0.0243 - val_loss: 0.0652\n",
            "Epoch 149/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0267 - val_loss: 0.1153\n",
            "Epoch 150/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0253 - val_loss: 0.1285\n",
            "Epoch 151/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0255 - val_loss: 0.0900\n",
            "Epoch 152/200\n",
            "50/50 [==============================] - 7s 145ms/step - loss: 0.0262 - val_loss: 0.1048\n",
            "Epoch 153/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0252 - val_loss: 0.0605\n",
            "Epoch 154/200\n",
            "50/50 [==============================] - 7s 147ms/step - loss: 0.0252 - val_loss: 0.1268\n",
            "Epoch 155/200\n",
            "50/50 [==============================] - 8s 161ms/step - loss: 0.0242 - val_loss: 0.0762\n",
            "Epoch 156/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0248 - val_loss: 0.0678\n",
            "Epoch 157/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0247 - val_loss: 0.1081\n",
            "Epoch 158/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0245 - val_loss: 0.1110\n",
            "Epoch 159/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0235 - val_loss: 0.0942\n",
            "Epoch 160/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0253 - val_loss: 0.1084\n",
            "Epoch 161/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0240 - val_loss: 0.0935\n",
            "Epoch 162/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0240 - val_loss: 0.1282\n",
            "Epoch 163/200\n",
            "50/50 [==============================] - 7s 138ms/step - loss: 0.0245 - val_loss: 0.0815\n",
            "Epoch 164/200\n",
            "50/50 [==============================] - 7s 144ms/step - loss: 0.0240 - val_loss: 0.0651\n",
            "Epoch 165/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0250 - val_loss: 0.1196\n",
            "Epoch 166/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0236 - val_loss: 0.0835\n",
            "Epoch 167/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0242 - val_loss: 0.0580\n",
            "Epoch 168/200\n",
            "50/50 [==============================] - 7s 138ms/step - loss: 0.0247 - val_loss: 0.1183\n",
            "Epoch 169/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0230 - val_loss: 0.1422\n",
            "Epoch 170/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0237 - val_loss: 0.0871\n",
            "Epoch 171/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0240 - val_loss: 0.1133\n",
            "Epoch 172/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0229 - val_loss: 0.0529\n",
            "Epoch 173/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0234 - val_loss: 0.1297\n",
            "Epoch 174/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0233 - val_loss: 0.1046\n",
            "Epoch 175/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0233 - val_loss: 0.0821\n",
            "Epoch 176/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0231 - val_loss: 0.1068\n",
            "Epoch 177/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0223 - val_loss: 0.1155\n",
            "Epoch 178/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0226 - val_loss: 0.1107\n",
            "Epoch 179/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0235 - val_loss: 0.1019\n",
            "Epoch 180/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0241 - val_loss: 0.0972\n",
            "Epoch 181/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0224 - val_loss: 0.1243\n",
            "Epoch 182/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0226 - val_loss: 0.1014\n",
            "Epoch 183/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0225 - val_loss: 0.0666\n",
            "Epoch 184/200\n",
            "50/50 [==============================] - 7s 146ms/step - loss: 0.0237 - val_loss: 0.1347\n",
            "Epoch 185/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0218 - val_loss: 0.0750\n",
            "Epoch 186/200\n",
            "50/50 [==============================] - 7s 146ms/step - loss: 0.0224 - val_loss: 0.0638\n",
            "Epoch 187/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0227 - val_loss: 0.1151\n",
            "Epoch 188/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0220 - val_loss: 0.1343\n",
            "Epoch 189/200\n",
            "50/50 [==============================] - 7s 140ms/step - loss: 0.0217 - val_loss: 0.0993\n",
            "Epoch 190/200\n",
            "50/50 [==============================] - 7s 138ms/step - loss: 0.0229 - val_loss: 0.1104\n",
            "Epoch 191/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0224 - val_loss: 0.0608\n",
            "Epoch 192/200\n",
            "50/50 [==============================] - 7s 143ms/step - loss: 0.0220 - val_loss: 0.1394\n",
            "Epoch 193/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0221 - val_loss: 0.1146\n",
            "Epoch 194/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0224 - val_loss: 0.0860\n",
            "Epoch 195/200\n",
            "50/50 [==============================] - 7s 144ms/step - loss: 0.0217 - val_loss: 0.1129\n",
            "Epoch 196/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0214 - val_loss: 0.1102\n",
            "Epoch 197/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0215 - val_loss: 0.0876\n",
            "Epoch 198/200\n",
            "50/50 [==============================] - 7s 142ms/step - loss: 0.0224 - val_loss: 0.1145\n",
            "Epoch 199/200\n",
            "50/50 [==============================] - 7s 141ms/step - loss: 0.0215 - val_loss: 0.0967\n",
            "Epoch 200/200\n",
            "50/50 [==============================] - 7s 139ms/step - loss: 0.0214 - val_loss: 0.1304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try smooting and plots"
      ],
      "metadata": {
        "id": "mkKgMX1YmXT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "smoothing_window_size = 100\n",
        "for di in range (0,3000,smoothing_window_size):\n",
        "  scaler.fit(float_data[di:di+smoothing_window_size,:])\n",
        "  float_data[di:di+smoothing_window_size,:] = scaler.transform(float_data[di:di+smoothing_window_size,:])\n",
        "scaler.fit(float_data[di+smoothing_window_size:,:])\n",
        "float_data[di+smoothing_window_size:,:] = scaler.tranform(float_data[di+smoothing_window_size:,:])\n",
        "#test data = scaler transform(float_data[3001:] transform test data"
      ],
      "metadata": {
        "id": "JtIzrPRhk1iM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval2 = model2.evaluate(test_gen, steps = test_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq26G-vVDrBM",
        "outputId": "3b1490bb-9e7f-4cfc-fa27-86cd80cdf8e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "527/527 [==============================] - 6s 11ms/step - loss: 0.0174\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "22BestTry.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}