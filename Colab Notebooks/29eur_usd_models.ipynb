{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wCsaCbLPovQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from itertools import chain\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#import keras_tuner as kt\n",
        "df = pd.read_csv(\"drive/MyDrive/Engineer's Project/output_eur_usd_trimmed.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.pop('Date')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ1dbA4wPxEb",
        "outputId": "ade6f0a4-4524-4e38-cb67-0e145c939c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       2010.11.15\n",
              "1       2010.11.16\n",
              "2       2010.11.17\n",
              "3       2010.11.18\n",
              "4       2010.11.19\n",
              "           ...    \n",
              "3537    2022.03.16\n",
              "3538    2022.03.17\n",
              "3539    2022.03.18\n",
              "3540    2022.03.20\n",
              "3541    2022.03.21\n",
              "Name: Date, Length: 3542, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "df_numpy = df.to_numpy() \n",
        "scaler = scaler.fit(df_numpy[:3000])\n",
        "df_scalled = scaler.transform(df_numpy)\n",
        "df_scalled = pd.DataFrame(df_scalled, columns=[\n",
        "  'Opening', 'High', 'Low', 'Closing','Momentum', 'Range', 'ohlc'])"
      ],
      "metadata": {
        "id": "3aZv5QNsPzZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_scalled[0:2500]\n",
        "df_val = df_scalled[2500:3000] #300\n",
        "df_game = df_scalled[3001:]"
      ],
      "metadata": {
        "id": "2-T-lnalP1lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lookback = 30 #15\n",
        "step = 1\n",
        "delay = 30 #0\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "sNw5B8AEP3L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "float_data = np.array(df_scalled).astype('float32')\n",
        "float_train_data = np.array(df_train).astype('float32')\n",
        "float_val_data = np.array(df_val).astype('float32')\n",
        "float_game_data = np.array(df_game).astype('float32')"
      ],
      "metadata": {
        "id": "WpBPEqDFP4P0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator(data, lookback, delay, min_index, max_index,shuffle=False, batch_size=128, step=1):\n",
        "  if max_index is None:\n",
        "    max_index = len(data) - delay - 1\n",
        "  i = min_index + lookback\n",
        "  while 1:\n",
        "    if shuffle:\n",
        "      rows = np.random.randint(\n",
        "        min_index + lookback, max_index, size=batch_size)\n",
        "    else:\n",
        "      if i + batch_size >= max_index:\n",
        "        i = min_index + lookback\n",
        "      rows = np.arange(i, min(i + batch_size, max_index))\n",
        "      i += len(rows)\n",
        "    samples = np.zeros((len(rows),lookback // step,data.shape[-1]))\n",
        "    targets = np.zeros((len(rows),))\n",
        "    for j, row in enumerate(rows):\n",
        "      indices = range(rows[j] - lookback, rows[j], step)\n",
        "      samples[j] = data[indices]\n",
        "      targets[j] = data[rows[j] + delay][3] \n",
        "    yield samples, targets"
      ],
      "metadata": {
        "id": "TDkeauKzP5YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = generator(float_train_data,\n",
        "lookback=lookback,\n",
        "delay=delay,\n",
        "min_index=0,\n",
        "max_index=2499 -delay,\n",
        "#shuffle=True,\n",
        "step=step,\n",
        "batch_size=batch_size)"
      ],
      "metadata": {
        "id": "-cH_3gp-P7H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_gen = generator(float_val_data,\n",
        "lookback=lookback,\n",
        "delay=delay,\n",
        "min_index=0,\n",
        "max_index=500-delay ,\n",
        "step=step,\n",
        "batch_size=batch_size)"
      ],
      "metadata": {
        "id": "YTAEN5KVP8Rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_gen = generator(float_game_data,\n",
        "lookback=lookback,\n",
        "delay=delay,\n",
        "min_index=0,\n",
        "max_index=540 -delay,\n",
        "step=step,\n",
        "batch_size=batch_size)"
      ],
      "metadata": {
        "id": "81ySVhBTP9mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_steps = (2500 - lookback)\n",
        "val_steps = (500 - lookback)\n",
        "test_steps = (541 - lookback)"
      ],
      "metadata": {
        "id": "c5fd1fxtP-zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(layers.LSTM(120,\n",
        "  activation='sigmoid',\n",
        "  input_shape=(None, float_train_data.shape[-1])))\n",
        "model.add(layers.Dense(160,\n",
        "  activation='sigmoid',))\n",
        "model.add(layers.Dense(1,\n",
        "  activation='sigmoid'))\n",
        "model.compile(optimizer= tf.keras.optimizers.RMSprop(0.01), loss='mae')\n",
        "history = model.fit(train_gen,\n",
        "  steps_per_epoch=100,\n",
        "  epochs=200,\n",
        "  validation_data=val_gen,\n",
        "  validation_steps=val_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3st2tc8QAXU",
        "outputId": "3d5f4f43-f437-435e-951e-188f278f31fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "100/100 [==============================] - 24s 224ms/step - loss: 0.3509 - val_loss: 0.4312\n",
            "Epoch 2/200\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.1736 - val_loss: 0.3324\n",
            "Epoch 3/200\n",
            "100/100 [==============================] - 24s 245ms/step - loss: 0.1374 - val_loss: 0.1013\n",
            "Epoch 4/200\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.1043 - val_loss: 0.2066\n",
            "Epoch 5/200\n",
            "100/100 [==============================] - 22s 226ms/step - loss: 0.0941 - val_loss: 0.0536\n",
            "Epoch 6/200\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.0862 - val_loss: 0.0463\n",
            "Epoch 7/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0808 - val_loss: 0.0484\n",
            "Epoch 8/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0802 - val_loss: 0.0425\n",
            "Epoch 9/200\n",
            "100/100 [==============================] - 24s 240ms/step - loss: 0.0767 - val_loss: 0.0811\n",
            "Epoch 10/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0738 - val_loss: 0.0246\n",
            "Epoch 11/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0728 - val_loss: 0.0264\n",
            "Epoch 12/200\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.0727 - val_loss: 0.0229\n",
            "Epoch 13/200\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0699 - val_loss: 0.1086\n",
            "Epoch 14/200\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0694 - val_loss: 0.0320\n",
            "Epoch 15/200\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0691 - val_loss: 0.0352\n",
            "Epoch 16/200\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0693 - val_loss: 0.0211\n",
            "Epoch 17/200\n",
            "100/100 [==============================] - 21s 216ms/step - loss: 0.0673 - val_loss: 0.0429\n",
            "Epoch 18/200\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0662 - val_loss: 0.0282\n",
            "Epoch 19/200\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0663 - val_loss: 0.0210\n",
            "Epoch 20/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0675 - val_loss: 0.0381\n",
            "Epoch 21/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0650 - val_loss: 0.0241\n",
            "Epoch 22/200\n",
            "100/100 [==============================] - 23s 236ms/step - loss: 0.0643 - val_loss: 0.0576\n",
            "Epoch 23/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0663 - val_loss: 0.0248\n",
            "Epoch 24/200\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.0651 - val_loss: 0.0266\n",
            "Epoch 25/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0643 - val_loss: 0.0255\n",
            "Epoch 26/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0637 - val_loss: 0.0300\n",
            "Epoch 27/200\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.0647 - val_loss: 0.0234\n",
            "Epoch 28/200\n",
            "100/100 [==============================] - 24s 240ms/step - loss: 0.0642 - val_loss: 0.0402\n",
            "Epoch 29/200\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.0632 - val_loss: 0.0246\n",
            "Epoch 30/200\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0630 - val_loss: 0.0296\n",
            "Epoch 31/200\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0639 - val_loss: 0.0216\n",
            "Epoch 32/200\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.0625 - val_loss: 0.0494\n",
            "Epoch 33/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0627 - val_loss: 0.0222\n",
            "Epoch 34/200\n",
            "100/100 [==============================] - 24s 238ms/step - loss: 0.0624 - val_loss: 0.0274\n",
            "Epoch 35/200\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0632 - val_loss: 0.0221\n",
            "Epoch 36/200\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0622 - val_loss: 0.0237\n",
            "Epoch 37/200\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.0612 - val_loss: 0.0234\n",
            "Epoch 38/200\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.0616 - val_loss: 0.0228\n",
            "Epoch 39/200\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.0630 - val_loss: 0.0263\n",
            "Epoch 40/200\n",
            "100/100 [==============================] - 24s 239ms/step - loss: 0.0613 - val_loss: 0.0231\n",
            "Epoch 41/200\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.0606 - val_loss: 0.0349\n",
            "Epoch 42/200\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.0619 - val_loss: 0.0245\n",
            "Epoch 43/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0627 - val_loss: 0.0266\n",
            "Epoch 44/200\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0621 - val_loss: 0.0263\n",
            "Epoch 45/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0616 - val_loss: 0.0240\n",
            "Epoch 46/200\n",
            "100/100 [==============================] - 24s 239ms/step - loss: 0.0624 - val_loss: 0.0216\n",
            "Epoch 47/200\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0621 - val_loss: 0.0256\n",
            "Epoch 48/200\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0615 - val_loss: 0.0249\n",
            "Epoch 49/200\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.0612 - val_loss: 0.0251\n",
            "Epoch 50/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0623 - val_loss: 0.0214\n",
            "Epoch 51/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0611 - val_loss: 0.0289\n",
            "Epoch 52/200\n",
            "100/100 [==============================] - 24s 242ms/step - loss: 0.0612 - val_loss: 0.0215\n",
            "Epoch 53/200\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.0610 - val_loss: 0.0262\n",
            "Epoch 54/200\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0622 - val_loss: 0.0216\n",
            "Epoch 55/200\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.0609 - val_loss: 0.0228\n",
            "Epoch 56/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0605 - val_loss: 0.0307\n",
            "Epoch 57/200\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0606 - val_loss: 0.0217\n",
            "Epoch 58/200\n",
            "100/100 [==============================] - 24s 242ms/step - loss: 0.0620 - val_loss: 0.0220\n",
            "Epoch 59/200\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0607 - val_loss: 0.0233\n",
            "Epoch 60/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0597 - val_loss: 0.0343\n",
            "Epoch 61/200\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0608 - val_loss: 0.0226\n",
            "Epoch 62/200\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0607 - val_loss: 0.0255\n",
            "Epoch 63/200\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0601 - val_loss: 0.0245\n",
            "Epoch 64/200\n",
            "100/100 [==============================] - 24s 239ms/step - loss: 0.0595 - val_loss: 0.0222\n",
            "Epoch 65/200\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0608 - val_loss: 0.0215\n",
            "Epoch 66/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0602 - val_loss: 0.0257\n",
            "Epoch 67/200\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.0595 - val_loss: 0.0234\n",
            "Epoch 68/200\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0589 - val_loss: 0.0255\n",
            "Epoch 69/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0609 - val_loss: 0.0215\n",
            "Epoch 70/200\n",
            "100/100 [==============================] - 23s 236ms/step - loss: 0.0592 - val_loss: 0.0280\n",
            "Epoch 71/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0592 - val_loss: 0.0217\n",
            "Epoch 72/200\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0588 - val_loss: 0.0268\n",
            "Epoch 73/200\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.0599 - val_loss: 0.0225\n",
            "Epoch 74/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0590 - val_loss: 0.0246\n",
            "Epoch 75/200\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.0584 - val_loss: 0.0218\n",
            "Epoch 76/200\n",
            "100/100 [==============================] - 22s 226ms/step - loss: 0.0587 - val_loss: 0.0221\n",
            "Epoch 77/200\n",
            "100/100 [==============================] - 24s 243ms/step - loss: 0.0602 - val_loss: 0.0282\n",
            "Epoch 78/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0587 - val_loss: 0.0216\n",
            "Epoch 79/200\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0580 - val_loss: 0.0239\n",
            "Epoch 80/200\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0593 - val_loss: 0.0250\n",
            "Epoch 81/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0593 - val_loss: 0.0288\n",
            "Epoch 82/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0586 - val_loss: 0.0219\n",
            "Epoch 83/200\n",
            "100/100 [==============================] - 25s 248ms/step - loss: 0.0580 - val_loss: 0.0218\n",
            "Epoch 84/200\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0591 - val_loss: 0.0269\n",
            "Epoch 85/200\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0589 - val_loss: 0.0327\n",
            "Epoch 86/200\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0585 - val_loss: 0.0233\n",
            "Epoch 87/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0579 - val_loss: 0.0290\n",
            "Epoch 88/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0593 - val_loss: 0.0254\n",
            "Epoch 89/200\n",
            "100/100 [==============================] - 24s 239ms/step - loss: 0.0582 - val_loss: 0.0358\n",
            "Epoch 90/200\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0583 - val_loss: 0.0221\n",
            "Epoch 91/200\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0579 - val_loss: 0.0294\n",
            "Epoch 92/200\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.0591 - val_loss: 0.0240\n",
            "Epoch 93/200\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.0581 - val_loss: 0.0304\n",
            "Epoch 94/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0575 - val_loss: 0.0227\n",
            "Epoch 95/200\n",
            "100/100 [==============================] - 24s 245ms/step - loss: 0.0577 - val_loss: 0.0234\n",
            "Epoch 96/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0592 - val_loss: 0.0321\n",
            "Epoch 97/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0579 - val_loss: 0.0225\n",
            "Epoch 98/200\n",
            "100/100 [==============================] - 22s 226ms/step - loss: 0.0570 - val_loss: 0.0241\n",
            "Epoch 99/200\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0581 - val_loss: 0.0268\n",
            "Epoch 100/200\n",
            "100/100 [==============================] - 22s 226ms/step - loss: 0.0582 - val_loss: 0.0303\n",
            "Epoch 101/200\n",
            "100/100 [==============================] - 24s 242ms/step - loss: 0.0577 - val_loss: 0.0217\n",
            "Epoch 102/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0570 - val_loss: 0.0230\n",
            "Epoch 103/200\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0580 - val_loss: 0.0285\n",
            "Epoch 104/200\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0578 - val_loss: 0.0341\n",
            "Epoch 105/200\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.0571 - val_loss: 0.0279\n",
            "Epoch 106/200\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0564 - val_loss: 0.0282\n",
            "Epoch 107/200\n",
            "100/100 [==============================] - 24s 245ms/step - loss: 0.0577 - val_loss: 0.0227\n",
            "Epoch 108/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0565 - val_loss: 0.0322\n",
            "Epoch 109/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0566 - val_loss: 0.0350\n",
            "Epoch 110/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0572 - val_loss: 0.0283\n",
            "Epoch 111/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0581 - val_loss: 0.0289\n",
            "Epoch 112/200\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0570 - val_loss: 0.0300\n",
            "Epoch 113/200\n",
            "100/100 [==============================] - 24s 244ms/step - loss: 0.0561 - val_loss: 0.0339\n",
            "Epoch 114/200\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0569 - val_loss: 0.0297\n",
            "Epoch 115/200\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0583 - val_loss: 0.0300\n",
            "Epoch 116/200\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0566 - val_loss: 0.0260\n",
            "Epoch 117/200\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0558 - val_loss: 0.0335\n",
            "Epoch 118/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0570 - val_loss: 0.0263\n",
            "Epoch 119/200\n",
            "100/100 [==============================] - 24s 246ms/step - loss: 0.0571 - val_loss: 0.0304\n",
            "Epoch 120/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0560 - val_loss: 0.0310\n",
            "Epoch 121/200\n",
            "100/100 [==============================] - 22s 226ms/step - loss: 0.0553 - val_loss: 0.0312\n",
            "Epoch 122/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0568 - val_loss: 0.0261\n",
            "Epoch 123/200\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0566 - val_loss: 0.0325\n",
            "Epoch 124/200\n",
            "100/100 [==============================] - 22s 226ms/step - loss: 0.0553 - val_loss: 0.0364\n",
            "Epoch 125/200\n",
            "100/100 [==============================] - 24s 241ms/step - loss: 0.0564 - val_loss: 0.0329\n",
            "Epoch 126/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0566 - val_loss: 0.0256\n",
            "Epoch 127/200\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0555 - val_loss: 0.0345\n",
            "Epoch 128/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0551 - val_loss: 0.0357\n",
            "Epoch 129/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0548 - val_loss: 0.0349\n",
            "Epoch 130/200\n",
            "100/100 [==============================] - 22s 226ms/step - loss: 0.0567 - val_loss: 0.0269\n",
            "Epoch 131/200\n",
            "100/100 [==============================] - 24s 244ms/step - loss: 0.0554 - val_loss: 0.0305\n",
            "Epoch 132/200\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0541 - val_loss: 0.0252\n",
            "Epoch 133/200\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0541 - val_loss: 0.0256\n",
            "Epoch 134/200\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0563 - val_loss: 0.0282\n",
            "Epoch 135/200\n",
            "100/100 [==============================] - 22s 226ms/step - loss: 0.0561 - val_loss: 0.0267\n",
            "Epoch 136/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0539 - val_loss: 0.0273\n",
            "Epoch 137/200\n",
            "100/100 [==============================] - 24s 241ms/step - loss: 0.0548 - val_loss: 0.0350\n",
            "Epoch 138/200\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.0552 - val_loss: 0.0303\n",
            "Epoch 139/200\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.0542 - val_loss: 0.0277\n",
            "Epoch 140/200\n",
            "100/100 [==============================] - 22s 226ms/step - loss: 0.0535 - val_loss: 0.0273\n",
            "Epoch 141/200\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0545 - val_loss: 0.0290\n",
            "Epoch 142/200\n",
            "100/100 [==============================] - 23s 232ms/step - loss: 0.0546 - val_loss: 0.0343\n",
            "Epoch 143/200\n",
            "100/100 [==============================] - 24s 246ms/step - loss: 0.0537 - val_loss: 0.0327\n",
            "Epoch 144/200\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.0530 - val_loss: 0.0307\n",
            "Epoch 145/200\n",
            "100/100 [==============================] - 22s 226ms/step - loss: 0.0546 - val_loss: 0.0290\n",
            "Epoch 146/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0542 - val_loss: 0.0342\n",
            "Epoch 147/200\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0533 - val_loss: 0.0350\n",
            "Epoch 148/200\n",
            "100/100 [==============================] - 22s 226ms/step - loss: 0.0528 - val_loss: 0.0420\n",
            "Epoch 149/200\n",
            "100/100 [==============================] - 25s 250ms/step - loss: 0.0543 - val_loss: 0.0275\n",
            "Epoch 150/200\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.0531 - val_loss: 0.0360\n",
            "Epoch 151/200\n",
            "100/100 [==============================] - 22s 226ms/step - loss: 0.0531 - val_loss: 0.0311\n",
            "Epoch 152/200\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.0529 - val_loss: 0.0263\n",
            "Epoch 153/200\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.0544 - val_loss: 0.0301\n",
            "Epoch 154/200\n",
            "100/100 [==============================] - 23s 233ms/step - loss: 0.0531 - val_loss: 0.0272\n",
            "Epoch 155/200\n",
            "100/100 [==============================] - 25s 248ms/step - loss: 0.0517 - val_loss: 0.0300\n",
            "Epoch 156/200\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0530 - val_loss: 0.0365\n",
            "Epoch 157/200\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.0535 - val_loss: 0.0338\n",
            "Epoch 158/200\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0523 - val_loss: 0.0269\n",
            "Epoch 159/200\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0513 - val_loss: 0.0289\n",
            "Epoch 160/200\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0530 - val_loss: 0.0288\n",
            "Epoch 161/200\n",
            "100/100 [==============================] - 25s 247ms/step - loss: 0.0531 - val_loss: 0.0344\n",
            "Epoch 162/200\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0514 - val_loss: 0.0323\n",
            "Epoch 163/200\n",
            "100/100 [==============================] - 22s 226ms/step - loss: 0.0509 - val_loss: 0.0327\n",
            "Epoch 164/200\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0519 - val_loss: 0.0292\n",
            "Epoch 165/200\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0521 - val_loss: 0.0330\n",
            "Epoch 166/200\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0509 - val_loss: 0.0465\n",
            "Epoch 167/200\n",
            "100/100 [==============================] - 24s 243ms/step - loss: 0.0512 - val_loss: 0.0383\n",
            "Epoch 168/200\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0523 - val_loss: 0.0291\n",
            "Epoch 169/200\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0509 - val_loss: 0.0390\n",
            "Epoch 170/200\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0503 - val_loss: 0.0281\n",
            "Epoch 171/200\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0501 - val_loss: 0.0297\n",
            "Epoch 172/200\n",
            "100/100 [==============================] - 25s 249ms/step - loss: 0.0519 - val_loss: 0.0391\n",
            "Epoch 173/200\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.0502 - val_loss: 0.0323\n",
            "Epoch 174/200\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0489 - val_loss: 0.0298\n",
            "Epoch 175/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0506 - val_loss: 0.0329\n",
            "Epoch 176/200\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0515 - val_loss: 0.0323\n",
            "Epoch 177/200\n",
            "100/100 [==============================] - 23s 233ms/step - loss: 0.0495 - val_loss: 0.0368\n",
            "Epoch 178/200\n",
            "100/100 [==============================] - 25s 247ms/step - loss: 0.0491 - val_loss: 0.0293\n",
            "Epoch 179/200\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0501 - val_loss: 0.0359\n",
            "Epoch 180/200\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0505 - val_loss: 0.0364\n",
            "Epoch 181/200\n",
            "100/100 [==============================] - 22s 226ms/step - loss: 0.0483 - val_loss: 0.0340\n",
            "Epoch 182/200\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.0484 - val_loss: 0.0354\n",
            "Epoch 183/200\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.0498 - val_loss: 0.0348\n",
            "Epoch 184/200\n",
            "100/100 [==============================] - 24s 241ms/step - loss: 0.0491 - val_loss: 0.0338\n",
            "Epoch 185/200\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0479 - val_loss: 0.0407\n",
            "Epoch 186/200\n",
            "100/100 [==============================] - 22s 226ms/step - loss: 0.0479 - val_loss: 0.0353\n",
            "Epoch 187/200\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0497 - val_loss: 0.0320\n",
            "Epoch 188/200\n",
            "100/100 [==============================] - 22s 226ms/step - loss: 0.0479 - val_loss: 0.0338\n",
            "Epoch 189/200\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0470 - val_loss: 0.0434\n",
            "Epoch 190/200\n",
            "100/100 [==============================] - 24s 239ms/step - loss: 0.0474 - val_loss: 0.0358\n",
            "Epoch 191/200\n",
            "100/100 [==============================] - 22s 226ms/step - loss: 0.0489 - val_loss: 0.0297\n",
            "Epoch 192/200\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.0462 - val_loss: 0.0320\n",
            "Epoch 193/200\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0457 - val_loss: 0.0360\n",
            "Epoch 194/200\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.0468 - val_loss: 0.0337\n",
            "Epoch 195/200\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0473 - val_loss: 0.0329\n",
            "Epoch 196/200\n",
            "100/100 [==============================] - 24s 240ms/step - loss: 0.0454 - val_loss: 0.0302\n",
            "Epoch 197/200\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0451 - val_loss: 0.0400\n",
            "Epoch 198/200\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0462 - val_loss: 0.0396\n",
            "Epoch 199/200\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.0467 - val_loss: 0.0330\n",
            "Epoch 200/200\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0447 - val_loss: 0.0359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval = model.evaluate(test_gen, steps = test_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CNM2DsNawD3",
        "outputId": "5c5201f8-2be6-47f9-ae3c-2ab74f6cadd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511/511 [==============================] - 20s 38ms/step - loss: 0.0401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"drive/MyDrive/Engineer's Project/longer_lstm_eur_usd.h5\")"
      ],
      "metadata": {
        "id": "oIv-Ykpaay4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(layers.GRU(140,\n",
        "  activation='sigmoid',\n",
        "  #dropout=0.1,\n",
        "  #recurrent_dropout=0.1,\n",
        "  return_sequences=True,\n",
        "  input_shape=(None, float_data.shape[-1])))\n",
        "model.add(layers.Dense(120,\n",
        "  activation='sigmoid',))\n",
        "model.add(layers.GRU(2,\n",
        "  activation='sigmoid',\n",
        "  #dropout=0.1,\n",
        "  #recurrent_dropout=0.1,\n",
        "  input_shape=(None, float_data.shape[-1])))\n",
        "model.add(layers.Dense(1,\n",
        "  activation='sigmoid'))\n",
        "model.compile(optimizer= tf.keras.optimizers.RMSprop(0.01), loss='mae')\n",
        "history = model.fit(train_gen,\n",
        "  steps_per_epoch=100,\n",
        "  epochs=200,\n",
        "  validation_data=val_gen,\n",
        "  validation_steps=val_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G35ptkINbENt",
        "outputId": "d3362d1a-ae11-477b-c2b0-197030a6853f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "100/100 [==============================] - 34s 294ms/step - loss: 0.2515 - val_loss: 0.4053\n",
            "Epoch 2/200\n",
            "100/100 [==============================] - 29s 291ms/step - loss: 0.1533 - val_loss: 0.1123\n",
            "Epoch 3/200\n",
            "100/100 [==============================] - 31s 317ms/step - loss: 0.1120 - val_loss: 0.0318\n",
            "Epoch 4/200\n",
            "100/100 [==============================] - 29s 295ms/step - loss: 0.0940 - val_loss: 0.0747\n",
            "Epoch 5/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0844 - val_loss: 0.0586\n",
            "Epoch 6/200\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0783 - val_loss: 0.0238\n",
            "Epoch 7/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0748 - val_loss: 0.0223\n",
            "Epoch 8/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0750 - val_loss: 0.0408\n",
            "Epoch 9/200\n",
            "100/100 [==============================] - 30s 302ms/step - loss: 0.0731 - val_loss: 0.0599\n",
            "Epoch 10/200\n",
            "100/100 [==============================] - 27s 276ms/step - loss: 0.0712 - val_loss: 0.0245\n",
            "Epoch 11/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 0.0701 - val_loss: 0.0712\n",
            "Epoch 12/200\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 0.0710 - val_loss: 0.0281\n",
            "Epoch 13/200\n",
            "100/100 [==============================] - 27s 273ms/step - loss: 0.0688 - val_loss: 0.0502\n",
            "Epoch 14/200\n",
            "100/100 [==============================] - 29s 294ms/step - loss: 0.0679 - val_loss: 0.0233\n",
            "Epoch 15/200\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0673 - val_loss: 0.0622\n",
            "Epoch 16/200\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 0.0682 - val_loss: 0.0245\n",
            "Epoch 17/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0664 - val_loss: 0.0408\n",
            "Epoch 18/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0652 - val_loss: 0.0232\n",
            "Epoch 19/200\n",
            "100/100 [==============================] - 30s 299ms/step - loss: 0.0655 - val_loss: 0.0233\n",
            "Epoch 20/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0666 - val_loss: 0.0391\n",
            "Epoch 21/200\n",
            "100/100 [==============================] - 27s 276ms/step - loss: 0.0646 - val_loss: 0.0232\n",
            "Epoch 22/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0634 - val_loss: 0.0303\n",
            "Epoch 23/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0648 - val_loss: 0.0283\n",
            "Epoch 24/200\n",
            "100/100 [==============================] - 30s 301ms/step - loss: 0.0645 - val_loss: 0.0350\n",
            "Epoch 25/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0632 - val_loss: 0.0250\n",
            "Epoch 26/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0622 - val_loss: 0.0249\n",
            "Epoch 27/200\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 0.0638 - val_loss: 0.0322\n",
            "Epoch 28/200\n",
            "100/100 [==============================] - 27s 276ms/step - loss: 0.0629 - val_loss: 0.0509\n",
            "Epoch 29/200\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0622 - val_loss: 0.0276\n",
            "Epoch 30/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 0.0615 - val_loss: 0.0688\n",
            "Epoch 31/200\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0629 - val_loss: 0.0275\n",
            "Epoch 32/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0617 - val_loss: 0.0563\n",
            "Epoch 33/200\n",
            "100/100 [==============================] - 27s 277ms/step - loss: 0.0614 - val_loss: 0.0241\n",
            "Epoch 34/200\n",
            "100/100 [==============================] - 30s 301ms/step - loss: 0.0608 - val_loss: 0.0710\n",
            "Epoch 35/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 0.0623 - val_loss: 0.0317\n",
            "Epoch 36/200\n",
            "100/100 [==============================] - 27s 277ms/step - loss: 0.0609 - val_loss: 0.0475\n",
            "Epoch 37/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0605 - val_loss: 0.0250\n",
            "Epoch 38/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0604 - val_loss: 0.0317\n",
            "Epoch 39/200\n",
            "100/100 [==============================] - 29s 295ms/step - loss: 0.0619 - val_loss: 0.0539\n",
            "Epoch 40/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0604 - val_loss: 0.0253\n",
            "Epoch 41/200\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 0.0594 - val_loss: 0.0297\n",
            "Epoch 42/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0605 - val_loss: 0.0330\n",
            "Epoch 43/200\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 0.0608 - val_loss: 0.0518\n",
            "Epoch 44/200\n",
            "100/100 [==============================] - 30s 302ms/step - loss: 0.0596 - val_loss: 0.0266\n",
            "Epoch 45/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0591 - val_loss: 0.0250\n",
            "Epoch 46/200\n",
            "100/100 [==============================] - 27s 276ms/step - loss: 0.0599 - val_loss: 0.0332\n",
            "Epoch 47/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0596 - val_loss: 0.0467\n",
            "Epoch 48/200\n",
            "100/100 [==============================] - 27s 276ms/step - loss: 0.0589 - val_loss: 0.0311\n",
            "Epoch 49/200\n",
            "100/100 [==============================] - 30s 297ms/step - loss: 0.0578 - val_loss: 0.0715\n",
            "Epoch 50/200\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0593 - val_loss: 0.0420\n",
            "Epoch 51/200\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0579 - val_loss: 0.0588\n",
            "Epoch 52/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 0.0575 - val_loss: 0.0317\n",
            "Epoch 53/200\n",
            "100/100 [==============================] - 27s 276ms/step - loss: 0.0566 - val_loss: 0.0883\n",
            "Epoch 54/200\n",
            "100/100 [==============================] - 30s 298ms/step - loss: 0.0578 - val_loss: 0.0325\n",
            "Epoch 55/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0566 - val_loss: 0.0441\n",
            "Epoch 56/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0557 - val_loss: 0.0368\n",
            "Epoch 57/200\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0557 - val_loss: 0.0377\n",
            "Epoch 58/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0568 - val_loss: 0.0652\n",
            "Epoch 59/200\n",
            "100/100 [==============================] - 29s 297ms/step - loss: 0.0559 - val_loss: 0.0378\n",
            "Epoch 60/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0547 - val_loss: 0.0321\n",
            "Epoch 61/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0553 - val_loss: 0.0497\n",
            "Epoch 62/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 0.0561 - val_loss: 0.0592\n",
            "Epoch 63/200\n",
            "100/100 [==============================] - 27s 273ms/step - loss: 0.0549 - val_loss: 0.0324\n",
            "Epoch 64/200\n",
            "100/100 [==============================] - 29s 293ms/step - loss: 0.0537 - val_loss: 0.0371\n",
            "Epoch 65/200\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0553 - val_loss: 0.0461\n",
            "Epoch 66/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0550 - val_loss: 0.0528\n",
            "Epoch 67/200\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0544 - val_loss: 0.0417\n",
            "Epoch 68/200\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 0.0537 - val_loss: 0.0798\n",
            "Epoch 69/200\n",
            "100/100 [==============================] - 30s 302ms/step - loss: 0.0553 - val_loss: 0.0395\n",
            "Epoch 70/200\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0541 - val_loss: 0.0694\n",
            "Epoch 71/200\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 0.0535 - val_loss: 0.0398\n",
            "Epoch 72/200\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0527 - val_loss: 0.0955\n",
            "Epoch 73/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0539 - val_loss: 0.0434\n",
            "Epoch 74/200\n",
            "100/100 [==============================] - 29s 290ms/step - loss: 0.0534 - val_loss: 0.0678\n",
            "Epoch 75/200\n",
            "100/100 [==============================] - 27s 272ms/step - loss: 0.0525 - val_loss: 0.0418\n",
            "Epoch 76/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0523 - val_loss: 0.0462\n",
            "Epoch 77/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 0.0526 - val_loss: 0.0614\n",
            "Epoch 78/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0526 - val_loss: 0.0316\n",
            "Epoch 79/200\n",
            "100/100 [==============================] - 29s 296ms/step - loss: 0.0501 - val_loss: 0.0358\n",
            "Epoch 80/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0511 - val_loss: 0.0447\n",
            "Epoch 81/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0510 - val_loss: 0.0452\n",
            "Epoch 82/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0494 - val_loss: 0.0303\n",
            "Epoch 83/200\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0507 - val_loss: 0.0330\n",
            "Epoch 84/200\n",
            "100/100 [==============================] - 29s 295ms/step - loss: 0.0490 - val_loss: 0.0468\n",
            "Epoch 85/200\n",
            "100/100 [==============================] - 27s 273ms/step - loss: 0.0496 - val_loss: 0.0529\n",
            "Epoch 86/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0536 - val_loss: 0.0345\n",
            "Epoch 87/200\n",
            "100/100 [==============================] - 27s 271ms/step - loss: 0.0472 - val_loss: 0.0670\n",
            "Epoch 88/200\n",
            "100/100 [==============================] - 27s 276ms/step - loss: 0.0489 - val_loss: 0.0436\n",
            "Epoch 89/200\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0485 - val_loss: 0.0374\n",
            "Epoch 90/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0466 - val_loss: 0.0312\n",
            "Epoch 91/200\n",
            "100/100 [==============================] - 27s 273ms/step - loss: 0.0467 - val_loss: 0.0914\n",
            "Epoch 92/200\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0465 - val_loss: 0.0320\n",
            "Epoch 93/200\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 0.0464 - val_loss: 0.0424\n",
            "Epoch 94/200\n",
            "100/100 [==============================] - 30s 297ms/step - loss: 0.0462 - val_loss: 0.0421\n",
            "Epoch 95/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0454 - val_loss: 0.0385\n",
            "Epoch 96/200\n",
            "100/100 [==============================] - 26s 266ms/step - loss: 0.0476 - val_loss: 0.0498\n",
            "Epoch 97/200\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0457 - val_loss: 0.0401\n",
            "Epoch 98/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0453 - val_loss: 0.0370\n",
            "Epoch 99/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0455 - val_loss: 0.0472\n",
            "Epoch 100/200\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0472 - val_loss: 0.0440\n",
            "Epoch 101/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0454 - val_loss: 0.0276\n",
            "Epoch 102/200\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0449 - val_loss: 0.0289\n",
            "Epoch 103/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 0.0444 - val_loss: 0.0428\n",
            "Epoch 104/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0424 - val_loss: 0.0504\n",
            "Epoch 105/200\n",
            "100/100 [==============================] - 30s 302ms/step - loss: 0.0469 - val_loss: 0.0377\n",
            "Epoch 106/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0429 - val_loss: 0.0447\n",
            "Epoch 107/200\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 0.0421 - val_loss: 0.0386\n",
            "Epoch 108/200\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 0.0414 - val_loss: 0.0418\n",
            "Epoch 109/200\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0432 - val_loss: 0.0464\n",
            "Epoch 110/200\n",
            "100/100 [==============================] - 29s 293ms/step - loss: 0.0420 - val_loss: 0.0738\n",
            "Epoch 111/200\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 0.0417 - val_loss: 0.0454\n",
            "Epoch 112/200\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 0.0427 - val_loss: 0.0333\n",
            "Epoch 113/200\n",
            "100/100 [==============================] - 27s 276ms/step - loss: 0.0398 - val_loss: 0.0357\n",
            "Epoch 114/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0402 - val_loss: 0.0414\n",
            "Epoch 115/200\n",
            "100/100 [==============================] - 29s 292ms/step - loss: 0.0411 - val_loss: 0.0355\n",
            "Epoch 116/200\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 0.0417 - val_loss: 0.0330\n",
            "Epoch 117/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0387 - val_loss: 0.0455\n",
            "Epoch 118/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 0.0391 - val_loss: 0.0429\n",
            "Epoch 119/200\n",
            "100/100 [==============================] - 27s 273ms/step - loss: 0.0399 - val_loss: 0.0373\n",
            "Epoch 120/200\n",
            "100/100 [==============================] - 30s 301ms/step - loss: 0.0390 - val_loss: 0.0352\n",
            "Epoch 121/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0370 - val_loss: 0.0308\n",
            "Epoch 122/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 0.0374 - val_loss: 0.0540\n",
            "Epoch 123/200\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0374 - val_loss: 0.0410\n",
            "Epoch 124/200\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 0.0361 - val_loss: 0.0450\n",
            "Epoch 125/200\n",
            "100/100 [==============================] - 30s 297ms/step - loss: 0.0356 - val_loss: 0.0656\n",
            "Epoch 126/200\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 0.0346 - val_loss: 0.0382\n",
            "Epoch 127/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0346 - val_loss: 0.0595\n",
            "Epoch 128/200\n",
            "100/100 [==============================] - 29s 290ms/step - loss: 0.0352 - val_loss: 0.0358\n",
            "Epoch 129/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0330 - val_loss: 0.0507\n",
            "Epoch 130/200\n",
            "100/100 [==============================] - 29s 292ms/step - loss: 0.0340 - val_loss: 0.0400\n",
            "Epoch 131/200\n",
            "100/100 [==============================] - 27s 276ms/step - loss: 0.0343 - val_loss: 0.0579\n",
            "Epoch 132/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 0.0328 - val_loss: 0.0396\n",
            "Epoch 133/200\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.0327 - val_loss: 0.0488\n",
            "Epoch 134/200\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0320 - val_loss: 0.0667\n",
            "Epoch 135/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0332 - val_loss: 0.0389\n",
            "Epoch 136/200\n",
            "100/100 [==============================] - 29s 292ms/step - loss: 0.0305 - val_loss: 0.0484\n",
            "Epoch 137/200\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0332 - val_loss: 0.0444\n",
            "Epoch 138/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0302 - val_loss: 0.0613\n",
            "Epoch 139/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 0.0309 - val_loss: 0.0330\n",
            "Epoch 140/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 0.0299 - val_loss: 0.0522\n",
            "Epoch 141/200\n",
            "100/100 [==============================] - 30s 298ms/step - loss: 0.0287 - val_loss: 0.0519\n",
            "Epoch 142/200\n",
            "100/100 [==============================] - 27s 273ms/step - loss: 0.0289 - val_loss: 0.0484\n",
            "Epoch 143/200\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 0.0295 - val_loss: 0.0351\n",
            "Epoch 144/200\n",
            "100/100 [==============================] - 27s 276ms/step - loss: 0.0278 - val_loss: 0.0524\n",
            "Epoch 145/200\n",
            "100/100 [==============================] - 27s 272ms/step - loss: 0.0302 - val_loss: 0.0383\n",
            "Epoch 146/200\n",
            "100/100 [==============================] - 30s 303ms/step - loss: 0.0284 - val_loss: 0.0470\n",
            "Epoch 147/200\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 0.0278 - val_loss: 0.0372\n",
            "Epoch 148/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0278 - val_loss: 0.0643\n",
            "Epoch 149/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0276 - val_loss: 0.0345\n",
            "Epoch 150/200\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 0.0283 - val_loss: 0.0370\n",
            "Epoch 151/200\n",
            "100/100 [==============================] - 30s 300ms/step - loss: 0.0256 - val_loss: 0.0482\n",
            "Epoch 152/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0268 - val_loss: 0.0579\n",
            "Epoch 153/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0272 - val_loss: 0.0411\n",
            "Epoch 154/200\n",
            "100/100 [==============================] - 27s 276ms/step - loss: 0.0267 - val_loss: 0.0345\n",
            "Epoch 155/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0254 - val_loss: 0.0366\n",
            "Epoch 156/200\n",
            "100/100 [==============================] - 29s 294ms/step - loss: 0.0247 - val_loss: 0.0425\n",
            "Epoch 157/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0258 - val_loss: 0.0416\n",
            "Epoch 158/200\n",
            "100/100 [==============================] - 27s 272ms/step - loss: 0.0244 - val_loss: 0.0300\n",
            "Epoch 159/200\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0245 - val_loss: 0.0445\n",
            "Epoch 160/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0243 - val_loss: 0.0779\n",
            "Epoch 161/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0241 - val_loss: 0.0495\n",
            "Epoch 162/200\n",
            "100/100 [==============================] - 29s 292ms/step - loss: 0.0245 - val_loss: 0.0337\n",
            "Epoch 163/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0238 - val_loss: 0.0428\n",
            "Epoch 164/200\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0241 - val_loss: 0.0352\n",
            "Epoch 165/200\n",
            "100/100 [==============================] - 27s 276ms/step - loss: 0.0243 - val_loss: 0.0325\n",
            "Epoch 166/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0234 - val_loss: 0.0483\n",
            "Epoch 167/200\n",
            "100/100 [==============================] - 29s 296ms/step - loss: 0.0232 - val_loss: 0.0948\n",
            "Epoch 168/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0224 - val_loss: 0.0393\n",
            "Epoch 169/200\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 0.0227 - val_loss: 0.0344\n",
            "Epoch 170/200\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0216 - val_loss: 0.0521\n",
            "Epoch 171/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0223 - val_loss: 0.0464\n",
            "Epoch 172/200\n",
            "100/100 [==============================] - 30s 304ms/step - loss: 0.0225 - val_loss: 0.0307\n",
            "Epoch 173/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0220 - val_loss: 0.0355\n",
            "Epoch 174/200\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 0.0211 - val_loss: 0.0366\n",
            "Epoch 175/200\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 0.0219 - val_loss: 0.0604\n",
            "Epoch 176/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0211 - val_loss: 0.0516\n",
            "Epoch 177/200\n",
            "100/100 [==============================] - 30s 298ms/step - loss: 0.0203 - val_loss: 0.0359\n",
            "Epoch 178/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 0.0210 - val_loss: 0.0400\n",
            "Epoch 179/200\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 0.0204 - val_loss: 0.0435\n",
            "Epoch 180/200\n",
            "100/100 [==============================] - 27s 276ms/step - loss: 0.0206 - val_loss: 0.0450\n",
            "Epoch 181/200\n",
            "100/100 [==============================] - 28s 286ms/step - loss: 0.0211 - val_loss: 0.0324\n",
            "Epoch 182/200\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 0.0197 - val_loss: 0.0328\n",
            "Epoch 183/200\n",
            "100/100 [==============================] - 30s 302ms/step - loss: 0.0192 - val_loss: 0.0428\n",
            "Epoch 184/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 0.0204 - val_loss: 0.0391\n",
            "Epoch 185/200\n",
            "100/100 [==============================] - 27s 271ms/step - loss: 0.0192 - val_loss: 0.0449\n",
            "Epoch 186/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0197 - val_loss: 0.0719\n",
            "Epoch 187/200\n",
            "100/100 [==============================] - 27s 272ms/step - loss: 0.0194 - val_loss: 0.0399\n",
            "Epoch 188/200\n",
            "100/100 [==============================] - 29s 291ms/step - loss: 0.0190 - val_loss: 0.0366\n",
            "Epoch 189/200\n",
            "100/100 [==============================] - 27s 276ms/step - loss: 0.0193 - val_loss: 0.0464\n",
            "Epoch 190/200\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 0.0184 - val_loss: 0.0392\n",
            "Epoch 191/200\n",
            "100/100 [==============================] - 28s 286ms/step - loss: 0.0181 - val_loss: 0.0429\n",
            "Epoch 192/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0189 - val_loss: 0.0377\n",
            "Epoch 193/200\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0180 - val_loss: 0.0456\n",
            "Epoch 194/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0178 - val_loss: 0.0548\n",
            "Epoch 195/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0181 - val_loss: 0.0378\n",
            "Epoch 196/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0176 - val_loss: 0.0503\n",
            "Epoch 197/200\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0179 - val_loss: 0.0384\n",
            "Epoch 198/200\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 0.0172 - val_loss: 0.0562\n",
            "Epoch 199/200\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0174 - val_loss: 0.0355\n",
            "Epoch 200/200\n",
            "100/100 [==============================] - 27s 276ms/step - loss: 0.0173 - val_loss: 0.0445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval = model.evaluate(test_gen, steps = test_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdMSIoZPohPU",
        "outputId": "e6f97404-9ec7-4fe7-d97d-b5bc851a00fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511/511 [==============================] - 22s 44ms/step - loss: 0.0468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"drive/MyDrive/Engineer's Project/longer_gru_eur_usd.h5\")"
      ],
      "metadata": {
        "id": "ASHQAkpZokZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(layers.LSTM(120,\n",
        "  activation='sigmoid',\n",
        "  #dropout=0.1,\n",
        "  #recurrent_dropout=0.1,\n",
        "  return_sequences=True,\n",
        "  input_shape=(None, float_data.shape[-1])))\n",
        "model.add(layers.GRU(5,\n",
        "  activation='sigmoid',\n",
        "  #dropout=0.1,\n",
        "  #recurrent_dropout=0.1,\n",
        "  input_shape=(None, float_data.shape[-1])))\n",
        "model.add(layers.Dense(160,\n",
        "  activation='sigmoid'))\n",
        "model.add(layers.Dense(1,\n",
        "  activation='sigmoid'))\n",
        "model.compile(optimizer= tf.keras.optimizers.RMSprop(0.01), loss='mae')\n",
        "history = model.fit(train_gen,\n",
        "  steps_per_epoch=100,\n",
        "  epochs=200,\n",
        "  validation_data=val_gen,\n",
        "  validation_steps=val_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUmeXm8zoulM",
        "outputId": "3a7c7626-c26f-4db6-c9ca-5eef0d7478ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "100/100 [==============================] - 29s 262ms/step - loss: 0.1978 - val_loss: 0.4975\n",
            "Epoch 2/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.1932 - val_loss: 0.3415\n",
            "Epoch 3/200\n",
            "100/100 [==============================] - 26s 262ms/step - loss: 0.1839 - val_loss: 0.0594\n",
            "Epoch 4/200\n",
            "100/100 [==============================] - 26s 260ms/step - loss: 0.1892 - val_loss: 0.0941\n",
            "Epoch 5/200\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.2014 - val_loss: 0.3471\n",
            "Epoch 6/200\n",
            "100/100 [==============================] - 26s 260ms/step - loss: 0.1782 - val_loss: 0.1163\n",
            "Epoch 7/200\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.1500 - val_loss: 0.0379\n",
            "Epoch 8/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.1430 - val_loss: 0.1992\n",
            "Epoch 9/200\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.1276 - val_loss: 0.2173\n",
            "Epoch 10/200\n",
            "100/100 [==============================] - 26s 262ms/step - loss: 0.1224 - val_loss: 0.0328\n",
            "Epoch 11/200\n",
            "100/100 [==============================] - 26s 259ms/step - loss: 0.1199 - val_loss: 0.0550\n",
            "Epoch 12/200\n",
            "100/100 [==============================] - 26s 266ms/step - loss: 0.1173 - val_loss: 0.0672\n",
            "Epoch 13/200\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.1133 - val_loss: 0.1685\n",
            "Epoch 14/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.1105 - val_loss: 0.0248\n",
            "Epoch 15/200\n",
            "100/100 [==============================] - 26s 257ms/step - loss: 0.1090 - val_loss: 0.0572\n",
            "Epoch 16/200\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.1081 - val_loss: 0.0250\n",
            "Epoch 17/200\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.1031 - val_loss: 0.0949\n",
            "Epoch 18/200\n",
            "100/100 [==============================] - 27s 272ms/step - loss: 0.1071 - val_loss: 0.0234\n",
            "Epoch 19/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.1155 - val_loss: 0.0261\n",
            "Epoch 20/200\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 0.1140 - val_loss: 0.0252\n",
            "Epoch 21/200\n",
            "100/100 [==============================] - 26s 266ms/step - loss: 0.1031 - val_loss: 0.0270\n",
            "Epoch 22/200\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.0954 - val_loss: 0.0474\n",
            "Epoch 23/200\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0933 - val_loss: 0.0220\n",
            "Epoch 24/200\n",
            "100/100 [==============================] - 26s 267ms/step - loss: 0.0909 - val_loss: 0.0286\n",
            "Epoch 25/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0910 - val_loss: 0.0326\n",
            "Epoch 26/200\n",
            "100/100 [==============================] - 26s 266ms/step - loss: 0.0896 - val_loss: 0.0306\n",
            "Epoch 27/200\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0899 - val_loss: 0.0221\n",
            "Epoch 28/200\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.0869 - val_loss: 0.0452\n",
            "Epoch 29/200\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0857 - val_loss: 0.0285\n",
            "Epoch 30/200\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 0.0851 - val_loss: 0.0338\n",
            "Epoch 31/200\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0858 - val_loss: 0.0255\n",
            "Epoch 32/200\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.0848 - val_loss: 0.0569\n",
            "Epoch 33/200\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0845 - val_loss: 0.0219\n",
            "Epoch 34/200\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0837 - val_loss: 0.0527\n",
            "Epoch 35/200\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.0851 - val_loss: 0.0223\n",
            "Epoch 36/200\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.0828 - val_loss: 0.0378\n",
            "Epoch 37/200\n",
            "100/100 [==============================] - 29s 291ms/step - loss: 0.0821 - val_loss: 0.0280\n",
            "Epoch 38/200\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0823 - val_loss: 0.0223\n",
            "Epoch 39/200\n",
            "100/100 [==============================] - 27s 271ms/step - loss: 0.0831 - val_loss: 0.0373\n",
            "Epoch 40/200\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.0799 - val_loss: 0.0233\n",
            "Epoch 41/200\n",
            "100/100 [==============================] - 27s 273ms/step - loss: 0.0802 - val_loss: 0.0316\n",
            "Epoch 42/200\n",
            "100/100 [==============================] - 26s 260ms/step - loss: 0.0810 - val_loss: 0.0224\n",
            "Epoch 43/200\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0789 - val_loss: 0.0348\n",
            "Epoch 44/200\n",
            "100/100 [==============================] - 27s 271ms/step - loss: 0.0783 - val_loss: 0.0285\n",
            "Epoch 45/200\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.0769 - val_loss: 0.0279\n",
            "Epoch 46/200\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 0.0777 - val_loss: 0.0255\n",
            "Epoch 47/200\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 0.0754 - val_loss: 0.0356\n",
            "Epoch 48/200\n",
            "100/100 [==============================] - 27s 271ms/step - loss: 0.0741 - val_loss: 0.0291\n",
            "Epoch 49/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0736 - val_loss: 0.0256\n",
            "Epoch 50/200\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 0.0742 - val_loss: 0.0248\n",
            "Epoch 51/200\n",
            "100/100 [==============================] - 26s 262ms/step - loss: 0.0723 - val_loss: 0.0369\n",
            "Epoch 52/200\n",
            "100/100 [==============================] - 26s 267ms/step - loss: 0.0725 - val_loss: 0.0254\n",
            "Epoch 53/200\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.0719 - val_loss: 0.0325\n",
            "Epoch 54/200\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.0717 - val_loss: 0.0240\n",
            "Epoch 55/200\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0702 - val_loss: 0.0270\n",
            "Epoch 56/200\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.0696 - val_loss: 0.0259\n",
            "Epoch 57/200\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0705 - val_loss: 0.0241\n",
            "Epoch 58/200\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0706 - val_loss: 0.0286\n",
            "Epoch 59/200\n",
            "100/100 [==============================] - 26s 257ms/step - loss: 0.0687 - val_loss: 0.0250\n",
            "Epoch 60/200\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0683 - val_loss: 0.0302\n",
            "Epoch 61/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0692 - val_loss: 0.0267\n",
            "Epoch 62/200\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0683 - val_loss: 0.0269\n",
            "Epoch 63/200\n",
            "100/100 [==============================] - 26s 266ms/step - loss: 0.0674 - val_loss: 0.0293\n",
            "Epoch 64/200\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0651 - val_loss: 0.0235\n",
            "Epoch 65/200\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0649 - val_loss: 0.0304\n",
            "Epoch 66/200\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0637 - val_loss: 0.0313\n",
            "Epoch 67/200\n",
            "100/100 [==============================] - 27s 277ms/step - loss: 0.0623 - val_loss: 0.0303\n",
            "Epoch 68/200\n",
            "100/100 [==============================] - 26s 262ms/step - loss: 0.0617 - val_loss: 0.0310\n",
            "Epoch 69/200\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.0621 - val_loss: 0.0225\n",
            "Epoch 70/200\n",
            "100/100 [==============================] - 26s 267ms/step - loss: 0.0607 - val_loss: 0.0237\n",
            "Epoch 71/200\n",
            "100/100 [==============================] - 26s 262ms/step - loss: 0.0600 - val_loss: 0.0314\n",
            "Epoch 72/200\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.0599 - val_loss: 0.0249\n",
            "Epoch 73/200\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0604 - val_loss: 0.0251\n",
            "Epoch 74/200\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0593 - val_loss: 0.0233\n",
            "Epoch 75/200\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0589 - val_loss: 0.0347\n",
            "Epoch 76/200\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.0588 - val_loss: 0.0279\n",
            "Epoch 77/200\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.0600 - val_loss: 0.0243\n",
            "Epoch 78/200\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.0581 - val_loss: 0.0328\n",
            "Epoch 79/200\n",
            "100/100 [==============================] - 27s 273ms/step - loss: 0.0577 - val_loss: 0.0690\n",
            "Epoch 80/200\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0590 - val_loss: 0.0239\n",
            "Epoch 81/200\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.0587 - val_loss: 0.0254\n",
            "Epoch 82/200\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.0579 - val_loss: 0.0264\n",
            "Epoch 83/200\n",
            "100/100 [==============================] - 26s 262ms/step - loss: 0.0588 - val_loss: 0.0415\n",
            "Epoch 84/200\n",
            "100/100 [==============================] - 26s 260ms/step - loss: 0.0580 - val_loss: 0.0255\n",
            "Epoch 85/200\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0590 - val_loss: 0.0302\n",
            "Epoch 86/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0581 - val_loss: 0.0295\n",
            "Epoch 87/200\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.0571 - val_loss: 0.0273\n",
            "Epoch 88/200\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0586 - val_loss: 0.0281\n",
            "Epoch 89/200\n",
            "100/100 [==============================] - 26s 259ms/step - loss: 0.0575 - val_loss: 0.0330\n",
            "Epoch 90/200\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.0562 - val_loss: 0.0311\n",
            "Epoch 91/200\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.0573 - val_loss: 0.0310\n",
            "Epoch 92/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0573 - val_loss: 0.0314\n",
            "Epoch 93/200\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0562 - val_loss: 0.0346\n",
            "Epoch 94/200\n",
            "100/100 [==============================] - 26s 266ms/step - loss: 0.0565 - val_loss: 0.0353\n",
            "Epoch 95/200\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0570 - val_loss: 0.0384\n",
            "Epoch 96/200\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0580 - val_loss: 0.0309\n",
            "Epoch 97/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 0.0564 - val_loss: 0.0292\n",
            "Epoch 98/200\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0572 - val_loss: 0.0656\n",
            "Epoch 99/200\n",
            "100/100 [==============================] - 26s 260ms/step - loss: 0.0610 - val_loss: 0.0340\n",
            "Epoch 100/200\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 0.0582 - val_loss: 0.0302\n",
            "Epoch 101/200\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.0558 - val_loss: 0.0369\n",
            "Epoch 102/200\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0559 - val_loss: 0.0496\n",
            "Epoch 103/200\n",
            "100/100 [==============================] - 27s 272ms/step - loss: 0.0562 - val_loss: 0.0309\n",
            "Epoch 104/200\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0562 - val_loss: 0.0370\n",
            "Epoch 105/200\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0553 - val_loss: 0.0338\n",
            "Epoch 106/200\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 0.0540 - val_loss: 0.0314\n",
            "Epoch 107/200\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.0598 - val_loss: 0.0282\n",
            "Epoch 108/200\n",
            "100/100 [==============================] - 27s 272ms/step - loss: 0.0539 - val_loss: 0.0296\n",
            "Epoch 109/200\n",
            "100/100 [==============================] - 27s 273ms/step - loss: 0.0590 - val_loss: 0.0253\n",
            "Epoch 110/200\n",
            "100/100 [==============================] - 29s 292ms/step - loss: 0.0612 - val_loss: 0.0270\n",
            "Epoch 111/200\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.0611 - val_loss: 0.0380\n",
            "Epoch 112/200\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0558 - val_loss: 0.0388\n",
            "Epoch 113/200\n",
            "100/100 [==============================] - 27s 276ms/step - loss: 0.0527 - val_loss: 0.0316\n",
            "Epoch 114/200\n",
            "100/100 [==============================] - 27s 272ms/step - loss: 0.0536 - val_loss: 0.0307\n",
            "Epoch 115/200\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 0.0538 - val_loss: 0.0347\n",
            "Epoch 116/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0553 - val_loss: 0.0341\n",
            "Epoch 117/200\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.0534 - val_loss: 0.0513\n",
            "Epoch 118/200\n",
            "100/100 [==============================] - 26s 266ms/step - loss: 0.0528 - val_loss: 0.0367\n",
            "Epoch 119/200\n",
            "100/100 [==============================] - 26s 266ms/step - loss: 0.0521 - val_loss: 0.0342\n",
            "Epoch 120/200\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0514 - val_loss: 0.0377\n",
            "Epoch 121/200\n",
            "100/100 [==============================] - 26s 262ms/step - loss: 0.0511 - val_loss: 0.0339\n",
            "Epoch 122/200\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.0517 - val_loss: 0.0329\n",
            "Epoch 123/200\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 0.0513 - val_loss: 0.0331\n",
            "Epoch 124/200\n",
            "100/100 [==============================] - 26s 259ms/step - loss: 0.0511 - val_loss: 0.0379\n",
            "Epoch 125/200\n",
            "100/100 [==============================] - 26s 266ms/step - loss: 0.0515 - val_loss: 0.0347\n",
            "Epoch 126/200\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0509 - val_loss: 0.0356\n",
            "Epoch 127/200\n",
            "100/100 [==============================] - 26s 266ms/step - loss: 0.0502 - val_loss: 0.0326\n",
            "Epoch 128/200\n",
            "100/100 [==============================] - 27s 272ms/step - loss: 0.0497 - val_loss: 0.0383\n",
            "Epoch 129/200\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0510 - val_loss: 0.0368\n",
            "Epoch 130/200\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.0493 - val_loss: 0.0340\n",
            "Epoch 131/200\n",
            "100/100 [==============================] - 26s 266ms/step - loss: 0.0491 - val_loss: 0.0384\n",
            "Epoch 132/200\n",
            "100/100 [==============================] - 26s 266ms/step - loss: 0.0488 - val_loss: 0.0363\n",
            "Epoch 133/200\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0501 - val_loss: 0.0343\n",
            "Epoch 134/200\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.0524 - val_loss: 0.0349\n",
            "Epoch 135/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0500 - val_loss: 0.0319\n",
            "Epoch 136/200\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.0474 - val_loss: 0.0534\n",
            "Epoch 137/200\n",
            "100/100 [==============================] - 26s 266ms/step - loss: 0.0485 - val_loss: 0.0335\n",
            "Epoch 138/200\n",
            "100/100 [==============================] - 26s 259ms/step - loss: 0.0475 - val_loss: 0.0388\n",
            "Epoch 139/200\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.0488 - val_loss: 0.0406\n",
            "Epoch 140/200\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.0465 - val_loss: 0.0401\n",
            "Epoch 141/200\n",
            "100/100 [==============================] - 29s 291ms/step - loss: 0.0483 - val_loss: 0.0339\n",
            "Epoch 142/200\n",
            "100/100 [==============================] - 26s 262ms/step - loss: 0.0463 - val_loss: 0.0567\n",
            "Epoch 143/200\n",
            "100/100 [==============================] - 26s 266ms/step - loss: 0.0469 - val_loss: 0.0356\n",
            "Epoch 144/200\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.0467 - val_loss: 0.0357\n",
            "Epoch 145/200\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.0466 - val_loss: 0.0403\n",
            "Epoch 146/200\n",
            "100/100 [==============================] - 27s 271ms/step - loss: 0.0466 - val_loss: 0.0673\n",
            "Epoch 147/200\n",
            "100/100 [==============================] - 29s 290ms/step - loss: 0.0452 - val_loss: 0.0355\n",
            "Epoch 148/200\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0458 - val_loss: 0.0419\n",
            "Epoch 149/200\n",
            "100/100 [==============================] - 26s 262ms/step - loss: 0.0460 - val_loss: 0.0440\n",
            "Epoch 150/200\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.0459 - val_loss: 0.0629\n",
            "Epoch 151/200\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0440 - val_loss: 0.0305\n",
            "Epoch 152/200\n",
            "100/100 [==============================] - 26s 262ms/step - loss: 0.0440 - val_loss: 0.0384\n",
            "Epoch 153/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0438 - val_loss: 0.0466\n",
            "Epoch 154/200\n",
            "100/100 [==============================] - 27s 271ms/step - loss: 0.0467 - val_loss: 0.0441\n",
            "Epoch 155/200\n",
            "100/100 [==============================] - 26s 266ms/step - loss: 0.0475 - val_loss: 0.0278\n",
            "Epoch 156/200\n",
            "100/100 [==============================] - 26s 260ms/step - loss: 0.0467 - val_loss: 0.0268\n",
            "Epoch 157/200\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0464 - val_loss: 0.0271\n",
            "Epoch 158/200\n",
            "100/100 [==============================] - 26s 260ms/step - loss: 0.0479 - val_loss: 0.0290\n",
            "Epoch 159/200\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0469 - val_loss: 0.0288\n",
            "Epoch 160/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0454 - val_loss: 0.0347\n",
            "Epoch 161/200\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0458 - val_loss: 0.0388\n",
            "Epoch 162/200\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.0453 - val_loss: 0.0311\n",
            "Epoch 163/200\n",
            "100/100 [==============================] - 26s 266ms/step - loss: 0.0461 - val_loss: 0.0457\n",
            "Epoch 164/200\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0448 - val_loss: 0.0290\n",
            "Epoch 165/200\n",
            "100/100 [==============================] - 26s 259ms/step - loss: 0.0454 - val_loss: 0.0656\n",
            "Epoch 166/200\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0439 - val_loss: 0.0310\n",
            "Epoch 167/200\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0442 - val_loss: 0.0414\n",
            "Epoch 168/200\n",
            "100/100 [==============================] - 26s 267ms/step - loss: 0.0425 - val_loss: 0.0357\n",
            "Epoch 169/200\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 0.0426 - val_loss: 0.0399\n",
            "Epoch 170/200\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0419 - val_loss: 0.0316\n",
            "Epoch 171/200\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0435 - val_loss: 0.0309\n",
            "Epoch 172/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0407 - val_loss: 0.0290\n",
            "Epoch 173/200\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0408 - val_loss: 0.0306\n",
            "Epoch 174/200\n",
            "100/100 [==============================] - 27s 272ms/step - loss: 0.0418 - val_loss: 0.0351\n",
            "Epoch 175/200\n",
            "100/100 [==============================] - 27s 272ms/step - loss: 0.0416 - val_loss: 0.0303\n",
            "Epoch 176/200\n",
            "100/100 [==============================] - 26s 266ms/step - loss: 0.0422 - val_loss: 0.0332\n",
            "Epoch 177/200\n",
            "100/100 [==============================] - 27s 271ms/step - loss: 0.0413 - val_loss: 0.0266\n",
            "Epoch 178/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0413 - val_loss: 0.0298\n",
            "Epoch 179/200\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.0416 - val_loss: 0.0268\n",
            "Epoch 180/200\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 0.0399 - val_loss: 0.0266\n",
            "Epoch 181/200\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 0.0401 - val_loss: 0.0307\n",
            "Epoch 182/200\n",
            "100/100 [==============================] - 26s 262ms/step - loss: 0.0404 - val_loss: 0.0375\n",
            "Epoch 183/200\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.0388 - val_loss: 0.0366\n",
            "Epoch 184/200\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.0411 - val_loss: 0.0366\n",
            "Epoch 185/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0395 - val_loss: 0.0253\n",
            "Epoch 186/200\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0382 - val_loss: 0.0486\n",
            "Epoch 187/200\n",
            "100/100 [==============================] - 26s 260ms/step - loss: 0.0386 - val_loss: 0.0362\n",
            "Epoch 188/200\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.0376 - val_loss: 0.0281\n",
            "Epoch 189/200\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.0378 - val_loss: 0.0256\n",
            "Epoch 190/200\n",
            "100/100 [==============================] - 25s 255ms/step - loss: 0.0382 - val_loss: 0.0261\n",
            "Epoch 191/200\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0369 - val_loss: 0.0404\n",
            "Epoch 192/200\n",
            "100/100 [==============================] - 26s 262ms/step - loss: 0.0364 - val_loss: 0.0322\n",
            "Epoch 193/200\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 0.0368 - val_loss: 0.0308\n",
            "Epoch 194/200\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.0373 - val_loss: 0.0352\n",
            "Epoch 195/200\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.0378 - val_loss: 0.0286\n",
            "Epoch 196/200\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.0366 - val_loss: 0.0272\n",
            "Epoch 197/200\n",
            "100/100 [==============================] - 29s 296ms/step - loss: 0.0364 - val_loss: 0.0325\n",
            "Epoch 198/200\n",
            "100/100 [==============================] - 26s 266ms/step - loss: 0.0361 - val_loss: 0.0302\n",
            "Epoch 199/200\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.0356 - val_loss: 0.0331\n",
            "Epoch 200/200\n",
            "100/100 [==============================] - 26s 260ms/step - loss: 0.0364 - val_loss: 0.0281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval = model.evaluate(test_gen, steps = test_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV2q_WR-12QF",
        "outputId": "8aa302ae-2e08-4f23-88c7-67a676c8995a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511/511 [==============================] - 23s 45ms/step - loss: 0.0472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"drive/MyDrive/Engineer's Project/longer_hybrid_eur_usd.h5\")"
      ],
      "metadata": {
        "id": "ErLbbeLY14Lx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}