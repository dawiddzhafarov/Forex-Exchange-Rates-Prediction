{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uqvufGBFnzo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from itertools import chain\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#import keras_tuner as kt\n",
        "df = pd.read_csv(\"drive/MyDrive/Engineer's Project/output_pln_usd.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q -U keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWjl0cq5kM-k",
        "outputId": "a9a6f840-3afc-4e97-ca06-b97854dc0d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▌                             | 10 kB 23.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 20 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 40 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 51 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 61 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 71 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 92 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 102 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 112 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 122 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 133 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133 kB 7.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt"
      ],
      "metadata": {
        "id": "wc1eMhAf2BVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.pop('usa_cpi')\n",
        "df.pop('pol_cpi')\n",
        "df.pop('usa_inter')\n",
        "df.pop('pol_inter')\n",
        "df.pop('Date')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS502CjzFpao",
        "outputId": "6d64457c-99ea-43bb-ea1c-081c62de8615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       2010.11.15\n",
              "1       2010.11.16\n",
              "2       2010.11.17\n",
              "3       2010.11.18\n",
              "4       2010.11.19\n",
              "           ...    \n",
              "3537    2022.03.27\n",
              "3538    2022.03.28\n",
              "3539    2022.03.29\n",
              "3540    2022.03.30\n",
              "3541    2022.03.31\n",
              "Name: Date, Length: 3542, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "df_numpy = df.to_numpy() \n",
        "#len(df_numpy[:2500])\n",
        "scaler1 = scaler.fit(df_numpy[:3001])\n",
        "df_scalled = scaler1.transform(df_numpy)\n",
        "#df_scaled_all = scaler.\n",
        "df_scalled = pd.DataFrame(df_scalled, columns=[\n",
        "  'Opening', 'High', 'Low', 'Closing','Momentum', 'Range', 'ohlc'])"
      ],
      "metadata": {
        "id": "WjNdiSHvFrav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_scalled[2100:3001]\n",
        "df_val = df_scalled[1700:2100] #300\n",
        "df_game = df_scalled[3001:]"
      ],
      "metadata": {
        "id": "kP5uMJkkQ5K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lookback = 30\n",
        "step = 1\n",
        "delay = 30\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "gAvZYxhrFsfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "float_data = np.array(df_scalled).astype('float32')"
      ],
      "metadata": {
        "id": "ysrqOl0zuEU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "float_game_data = np.array(df_game).astype('float32')"
      ],
      "metadata": {
        "id": "0lTEwaHIFD9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(float_train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWASkeXaF7LG",
        "outputId": "62b0333d-fea5-4695-a8e4-61a17ebbf844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "901"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(float_game_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cXsIJ4CjF5e",
        "outputId": "644d559b-aa89-4e62-c898-d3cfd53aafce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "541"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(float_val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_QPKvsYjPs7",
        "outputId": "3dfe3605-a748-4e81-9c0a-70241e7553e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_train_data = np.array(df_train).astype('float32')"
      ],
      "metadata": {
        "id": "Bf5lAsXNFPdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "float_val_data = np.array(df_val).astype('float32')"
      ],
      "metadata": {
        "id": "ExVL8hPCFQPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator(data, lookback, delay, min_index, max_index,shuffle=False, batch_size=128, step=1):\n",
        "  if max_index is None:\n",
        "    max_index = len(data) - delay - 1\n",
        "  i = min_index + lookback\n",
        "  while 1:\n",
        "    if shuffle:\n",
        "      rows = np.random.randint(\n",
        "        min_index + lookback, max_index, size=batch_size)\n",
        "    else:\n",
        "      if i + batch_size >= max_index:\n",
        "        i = min_index + lookback\n",
        "      rows = np.arange(i, min(i + batch_size, max_index))\n",
        "      i += len(rows)\n",
        "    samples = np.zeros((len(rows),lookback // step,data.shape[-1]))\n",
        "    targets = np.zeros((len(rows),))\n",
        "    for j, row in enumerate(rows):\n",
        "      indices = range(rows[j] - lookback, rows[j], step)\n",
        "      samples[j] = data[indices]\n",
        "      targets[j] = data[rows[j] + delay][3] \n",
        "    yield samples, targets"
      ],
      "metadata": {
        "id": "gb3c6vLLFucu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = generator(float_train_data,\n",
        "lookback=lookback,\n",
        "delay=delay,\n",
        "min_index=0,\n",
        "max_index=900 - delay,\n",
        "#shuffle=True,\n",
        "step=step,\n",
        "batch_size=batch_size)"
      ],
      "metadata": {
        "id": "UH5cZe3aFvc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_gen = generator(float_val_data,\n",
        "lookback=lookback,\n",
        "delay=delay,\n",
        "min_index=0,\n",
        "max_index=399 - delay,\n",
        "step=step,\n",
        "batch_size=batch_size)"
      ],
      "metadata": {
        "id": "jigLWVSgFwUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_gen = generator(float_data,\n",
        "lookback=lookback,\n",
        "delay=delay,\n",
        "min_index=3001,\n",
        "max_index=3541 - delay,\n",
        "step=step,\n",
        "batch_size=batch_size)"
      ],
      "metadata": {
        "id": "uQHe5fQrFxPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_steps = (399 - lookback)\n",
        "test_steps = (3541 - 3001 - lookback)"
      ],
      "metadata": {
        "id": "_ZToRnw0FyKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "P8fwLlIJV-a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(layers.LSTM(120,\n",
        "  activation='sigmoid',\n",
        " # dropout=0.2,\n",
        "  #recurrent_dropout=0.1,\n",
        "  input_shape=(None, float_train_data.shape[-1])))\n",
        "model.add(layers.Dense(160,\n",
        "  activation='sigmoid',))\n",
        "model.add(layers.Dense(1,\n",
        "  activation='sigmoid'))\n",
        "model.compile(optimizer= tf.keras.optimizers.RMSprop(0.01), loss='mae')\n",
        "history = model.fit(train_gen,\n",
        "  steps_per_epoch=200,\n",
        "  epochs=200,\n",
        "  validation_data=val_gen,\n",
        "  validation_steps=val_steps)"
      ],
      "metadata": {
        "id": "YMH209BsFzDq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbafc64a-9d42-400d-c4dc-53ec60c1d7bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "200/200 [==============================] - 28s 129ms/step - loss: 0.1707 - val_loss: 0.2202\n",
            "Epoch 2/200\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.0851 - val_loss: 0.1112\n",
            "Epoch 3/200\n",
            "200/200 [==============================] - 25s 126ms/step - loss: 0.0679 - val_loss: 0.0601\n",
            "Epoch 4/200\n",
            "200/200 [==============================] - 28s 141ms/step - loss: 0.0571 - val_loss: 0.0842\n",
            "Epoch 5/200\n",
            "200/200 [==============================] - 25s 126ms/step - loss: 0.0512 - val_loss: 0.0763\n",
            "Epoch 6/200\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.0489 - val_loss: 0.0744\n",
            "Epoch 7/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0480 - val_loss: 0.0702\n",
            "Epoch 8/200\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.0457 - val_loss: 0.0763\n",
            "Epoch 9/200\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.0446 - val_loss: 0.0693\n",
            "Epoch 10/200\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.0426 - val_loss: 0.0786\n",
            "Epoch 11/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0460 - val_loss: 0.0696\n",
            "Epoch 12/200\n",
            "200/200 [==============================] - 27s 137ms/step - loss: 0.0418 - val_loss: 0.0677\n",
            "Epoch 13/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0406 - val_loss: 0.0671\n",
            "Epoch 14/200\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.0429 - val_loss: 0.0720\n",
            "Epoch 15/200\n",
            "200/200 [==============================] - 25s 128ms/step - loss: 0.0401 - val_loss: 0.0667\n",
            "Epoch 16/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0395 - val_loss: 0.0721\n",
            "Epoch 17/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0398 - val_loss: 0.0773\n",
            "Epoch 18/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0404 - val_loss: 0.0672\n",
            "Epoch 19/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0387 - val_loss: 0.0700\n",
            "Epoch 20/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0381 - val_loss: 0.0960\n",
            "Epoch 21/200\n",
            "200/200 [==============================] - 27s 137ms/step - loss: 0.0380 - val_loss: 0.0704\n",
            "Epoch 22/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0376 - val_loss: 0.0699\n",
            "Epoch 23/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0374 - val_loss: 0.0887\n",
            "Epoch 24/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0372 - val_loss: 0.0728\n",
            "Epoch 25/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0371 - val_loss: 0.0782\n",
            "Epoch 26/200\n",
            "200/200 [==============================] - 27s 133ms/step - loss: 0.0365 - val_loss: 0.0769\n",
            "Epoch 27/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0367 - val_loss: 0.0723\n",
            "Epoch 28/200\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.0364 - val_loss: 0.0754\n",
            "Epoch 29/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0361 - val_loss: 0.0764\n",
            "Epoch 30/200\n",
            "200/200 [==============================] - 27s 137ms/step - loss: 0.0366 - val_loss: 0.0739\n",
            "Epoch 31/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0358 - val_loss: 0.0748\n",
            "Epoch 32/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0356 - val_loss: 0.0981\n",
            "Epoch 33/200\n",
            "200/200 [==============================] - 25s 126ms/step - loss: 0.0357 - val_loss: 0.0741\n",
            "Epoch 34/200\n",
            "200/200 [==============================] - 25s 126ms/step - loss: 0.0355 - val_loss: 0.0799\n",
            "Epoch 35/200\n",
            "200/200 [==============================] - 25s 126ms/step - loss: 0.0354 - val_loss: 0.0790\n",
            "Epoch 36/200\n",
            "200/200 [==============================] - 25s 126ms/step - loss: 0.0356 - val_loss: 0.0757\n",
            "Epoch 37/200\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.0355 - val_loss: 0.0792\n",
            "Epoch 38/200\n",
            "200/200 [==============================] - 27s 137ms/step - loss: 0.0353 - val_loss: 0.0986\n",
            "Epoch 39/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0353 - val_loss: 0.0764\n",
            "Epoch 40/200\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.0350 - val_loss: 0.0812\n",
            "Epoch 41/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0349 - val_loss: 0.0897\n",
            "Epoch 42/200\n",
            "200/200 [==============================] - 25s 128ms/step - loss: 0.0349 - val_loss: 0.0786\n",
            "Epoch 43/200\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.0351 - val_loss: 0.0910\n",
            "Epoch 44/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0347 - val_loss: 0.1012\n",
            "Epoch 45/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0346 - val_loss: 0.0827\n",
            "Epoch 46/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0351 - val_loss: 0.0934\n",
            "Epoch 47/200\n",
            "200/200 [==============================] - 27s 137ms/step - loss: 0.0340 - val_loss: 0.0823\n",
            "Epoch 48/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0347 - val_loss: 0.0815\n",
            "Epoch 49/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0339 - val_loss: 0.0786\n",
            "Epoch 50/200\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.0338 - val_loss: 0.1129\n",
            "Epoch 51/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0344 - val_loss: 0.0822\n",
            "Epoch 52/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0339 - val_loss: 0.0811\n",
            "Epoch 53/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0347 - val_loss: 0.1101\n",
            "Epoch 54/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0338 - val_loss: 0.0860\n",
            "Epoch 55/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0345 - val_loss: 0.0958\n",
            "Epoch 56/200\n",
            "200/200 [==============================] - 28s 139ms/step - loss: 0.0333 - val_loss: 0.0971\n",
            "Epoch 57/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0338 - val_loss: 0.0823\n",
            "Epoch 58/200\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.0337 - val_loss: 0.0878\n",
            "Epoch 59/200\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.0334 - val_loss: 0.1160\n",
            "Epoch 60/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0335 - val_loss: 0.0795\n",
            "Epoch 61/200\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.0353 - val_loss: 0.0843\n",
            "Epoch 62/200\n",
            "200/200 [==============================] - 25s 126ms/step - loss: 0.0410 - val_loss: 0.1205\n",
            "Epoch 63/200\n",
            "200/200 [==============================] - 25s 126ms/step - loss: 0.0342 - val_loss: 0.0767\n",
            "Epoch 64/200\n",
            "200/200 [==============================] - 27s 137ms/step - loss: 0.0337 - val_loss: 0.0743\n",
            "Epoch 65/200\n",
            "200/200 [==============================] - 25s 128ms/step - loss: 0.0332 - val_loss: 0.1098\n",
            "Epoch 66/200\n",
            "200/200 [==============================] - 25s 128ms/step - loss: 0.0340 - val_loss: 0.0728\n",
            "Epoch 67/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0328 - val_loss: 0.0728\n",
            "Epoch 68/200\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.0329 - val_loss: 0.0884\n",
            "Epoch 69/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0344 - val_loss: 0.0755\n",
            "Epoch 70/200\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.0332 - val_loss: 0.0751\n",
            "Epoch 71/200\n",
            "200/200 [==============================] - 25s 126ms/step - loss: 0.0360 - val_loss: 0.1094\n",
            "Epoch 72/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0333 - val_loss: 0.0764\n",
            "Epoch 73/200\n",
            "200/200 [==============================] - 28s 139ms/step - loss: 0.0334 - val_loss: 0.0846\n",
            "Epoch 74/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0327 - val_loss: 0.0828\n",
            "Epoch 75/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0327 - val_loss: 0.0808\n",
            "Epoch 76/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0321 - val_loss: 0.0834\n",
            "Epoch 77/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0328 - val_loss: 0.0862\n",
            "Epoch 78/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0341 - val_loss: 0.0813\n",
            "Epoch 79/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0327 - val_loss: 0.0888\n",
            "Epoch 80/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0333 - val_loss: 0.0819\n",
            "Epoch 81/200\n",
            "200/200 [==============================] - 28s 140ms/step - loss: 0.0322 - val_loss: 0.0820\n",
            "Epoch 82/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0325 - val_loss: 0.0999\n",
            "Epoch 83/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0321 - val_loss: 0.0820\n",
            "Epoch 84/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0327 - val_loss: 0.0830\n",
            "Epoch 85/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0318 - val_loss: 0.0771\n",
            "Epoch 86/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0334 - val_loss: 0.0861\n",
            "Epoch 87/200\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0352 - val_loss: 0.0789\n",
            "Epoch 88/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0323 - val_loss: 0.0840\n",
            "Epoch 89/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0317 - val_loss: 0.0857\n",
            "Epoch 90/200\n",
            "200/200 [==============================] - 28s 141ms/step - loss: 0.0313 - val_loss: 0.0753\n",
            "Epoch 91/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0312 - val_loss: 0.0766\n",
            "Epoch 92/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0303 - val_loss: 0.0940\n",
            "Epoch 93/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0313 - val_loss: 0.0823\n",
            "Epoch 94/200\n",
            "200/200 [==============================] - 26s 132ms/step - loss: 0.0307 - val_loss: 0.0821\n",
            "Epoch 95/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0302 - val_loss: 0.0898\n",
            "Epoch 96/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0306 - val_loss: 0.0750\n",
            "Epoch 97/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0300 - val_loss: 0.0815\n",
            "Epoch 98/200\n",
            "200/200 [==============================] - 28s 140ms/step - loss: 0.0303 - val_loss: 0.0864\n",
            "Epoch 99/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0301 - val_loss: 0.0780\n",
            "Epoch 100/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0298 - val_loss: 0.0794\n",
            "Epoch 101/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0297 - val_loss: 0.0817\n",
            "Epoch 102/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0299 - val_loss: 0.0764\n",
            "Epoch 103/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0299 - val_loss: 0.0872\n",
            "Epoch 104/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0292 - val_loss: 0.0852\n",
            "Epoch 105/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0296 - val_loss: 0.0841\n",
            "Epoch 106/200\n",
            "200/200 [==============================] - 28s 141ms/step - loss: 0.0297 - val_loss: 0.0845\n",
            "Epoch 107/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0295 - val_loss: 0.0846\n",
            "Epoch 108/200\n",
            "200/200 [==============================] - 26s 129ms/step - loss: 0.0295 - val_loss: 0.0840\n",
            "Epoch 109/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0288 - val_loss: 0.0877\n",
            "Epoch 110/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0288 - val_loss: 0.0856\n",
            "Epoch 111/200\n",
            "200/200 [==============================] - 26s 132ms/step - loss: 0.0288 - val_loss: 0.0819\n",
            "Epoch 112/200\n",
            "200/200 [==============================] - 26s 132ms/step - loss: 0.0287 - val_loss: 0.0853\n",
            "Epoch 113/200\n",
            "200/200 [==============================] - 26s 132ms/step - loss: 0.0284 - val_loss: 0.0926\n",
            "Epoch 114/200\n",
            "200/200 [==============================] - 28s 141ms/step - loss: 0.0287 - val_loss: 0.0897\n",
            "Epoch 115/200\n",
            "200/200 [==============================] - 26s 132ms/step - loss: 0.0292 - val_loss: 0.0905\n",
            "Epoch 116/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0280 - val_loss: 0.1017\n",
            "Epoch 117/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0278 - val_loss: 0.0793\n",
            "Epoch 118/200\n",
            "200/200 [==============================] - 26s 132ms/step - loss: 0.0280 - val_loss: 0.0934\n",
            "Epoch 119/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0283 - val_loss: 0.0959\n",
            "Epoch 120/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0276 - val_loss: 0.0770\n",
            "Epoch 121/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0275 - val_loss: 0.0854\n",
            "Epoch 122/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0270 - val_loss: 0.0952\n",
            "Epoch 123/200\n",
            "200/200 [==============================] - 29s 145ms/step - loss: 0.0272 - val_loss: 0.0817\n",
            "Epoch 124/200\n",
            "200/200 [==============================] - 27s 133ms/step - loss: 0.0260 - val_loss: 0.0872\n",
            "Epoch 125/200\n",
            "200/200 [==============================] - 26s 133ms/step - loss: 0.0261 - val_loss: 0.1008\n",
            "Epoch 126/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0259 - val_loss: 0.0889\n",
            "Epoch 127/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0261 - val_loss: 0.0799\n",
            "Epoch 128/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0260 - val_loss: 0.0973\n",
            "Epoch 129/200\n",
            "200/200 [==============================] - 26s 132ms/step - loss: 0.0256 - val_loss: 0.0809\n",
            "Epoch 130/200\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.0258 - val_loss: 0.0827\n",
            "Epoch 131/200\n",
            "200/200 [==============================] - 29s 145ms/step - loss: 0.0246 - val_loss: 0.0829\n",
            "Epoch 132/200\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.0256 - val_loss: 0.0769\n",
            "Epoch 133/200\n",
            "200/200 [==============================] - 28s 138ms/step - loss: 0.0260 - val_loss: 0.0851\n",
            "Epoch 134/200\n",
            "200/200 [==============================] - 26s 132ms/step - loss: 0.0244 - val_loss: 0.0964\n",
            "Epoch 135/200\n",
            "200/200 [==============================] - 26s 132ms/step - loss: 0.0242 - val_loss: 0.0893\n",
            "Epoch 136/200\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.0235 - val_loss: 0.0737\n",
            "Epoch 137/200\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.0239 - val_loss: 0.0937\n",
            "Epoch 138/200\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.0239 - val_loss: 0.0877\n",
            "Epoch 139/200\n",
            "200/200 [==============================] - 29s 143ms/step - loss: 0.0237 - val_loss: 0.0895\n",
            "Epoch 140/200\n",
            "200/200 [==============================] - 27s 133ms/step - loss: 0.0232 - val_loss: 0.1034\n",
            "Epoch 141/200\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.0234 - val_loss: 0.0849\n",
            "Epoch 142/200\n",
            "200/200 [==============================] - 26s 133ms/step - loss: 0.0238 - val_loss: 0.0935\n",
            "Epoch 143/200\n",
            "200/200 [==============================] - 26s 132ms/step - loss: 0.0232 - val_loss: 0.0908\n",
            "Epoch 144/200\n",
            "200/200 [==============================] - 26s 132ms/step - loss: 0.0227 - val_loss: 0.0902\n",
            "Epoch 145/200\n",
            "200/200 [==============================] - 27s 133ms/step - loss: 0.0222 - val_loss: 0.0751\n",
            "Epoch 146/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0275 - val_loss: 0.0981\n",
            "Epoch 147/200\n",
            "200/200 [==============================] - 28s 141ms/step - loss: 0.0225 - val_loss: 0.0857\n",
            "Epoch 148/200\n",
            "200/200 [==============================] - 26s 133ms/step - loss: 0.0221 - val_loss: 0.0912\n",
            "Epoch 149/200\n",
            "200/200 [==============================] - 27s 133ms/step - loss: 0.0217 - val_loss: 0.0985\n",
            "Epoch 150/200\n",
            "200/200 [==============================] - 26s 132ms/step - loss: 0.0220 - val_loss: 0.0828\n",
            "Epoch 151/200\n",
            "200/200 [==============================] - 26s 133ms/step - loss: 0.0217 - val_loss: 0.0970\n",
            "Epoch 152/200\n",
            "200/200 [==============================] - 27s 133ms/step - loss: 0.0215 - val_loss: 0.1001\n",
            "Epoch 153/200\n",
            "200/200 [==============================] - 27s 133ms/step - loss: 0.0214 - val_loss: 0.0860\n",
            "Epoch 154/200\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.0208 - val_loss: 0.0835\n",
            "Epoch 155/200\n",
            "200/200 [==============================] - 28s 142ms/step - loss: 0.0205 - val_loss: 0.0999\n",
            "Epoch 156/200\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.0205 - val_loss: 0.0923\n",
            "Epoch 157/200\n",
            "200/200 [==============================] - 27s 136ms/step - loss: 0.0199 - val_loss: 0.0712\n",
            "Epoch 158/200\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.0202 - val_loss: 0.0859\n",
            "Epoch 159/200\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.0196 - val_loss: 0.0837\n",
            "Epoch 160/200\n",
            "200/200 [==============================] - 31s 156ms/step - loss: 0.0194 - val_loss: 0.0849\n",
            "Epoch 161/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0196 - val_loss: 0.0910\n",
            "Epoch 162/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0204 - val_loss: 0.0802\n",
            "Epoch 163/200\n",
            "200/200 [==============================] - 28s 140ms/step - loss: 0.0190 - val_loss: 0.0884\n",
            "Epoch 164/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0189 - val_loss: 0.0756\n",
            "Epoch 165/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0202 - val_loss: 0.0791\n",
            "Epoch 166/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0273 - val_loss: 0.0717\n",
            "Epoch 167/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0246 - val_loss: 0.0940\n",
            "Epoch 168/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0191 - val_loss: 0.0804\n",
            "Epoch 169/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0184 - val_loss: 0.0876\n",
            "Epoch 170/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0186 - val_loss: 0.0844\n",
            "Epoch 171/200\n",
            "200/200 [==============================] - 28s 139ms/step - loss: 0.0183 - val_loss: 0.1037\n",
            "Epoch 172/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0173 - val_loss: 0.0772\n",
            "Epoch 173/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0176 - val_loss: 0.0941\n",
            "Epoch 174/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0179 - val_loss: 0.0787\n",
            "Epoch 175/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0177 - val_loss: 0.0859\n",
            "Epoch 176/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0174 - val_loss: 0.0814\n",
            "Epoch 177/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0174 - val_loss: 0.0858\n",
            "Epoch 178/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0183 - val_loss: 0.0942\n",
            "Epoch 179/200\n",
            "200/200 [==============================] - 28s 139ms/step - loss: 0.0171 - val_loss: 0.0953\n",
            "Epoch 180/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0171 - val_loss: 0.0835\n",
            "Epoch 181/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0171 - val_loss: 0.0907\n",
            "Epoch 182/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0169 - val_loss: 0.0941\n",
            "Epoch 183/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0169 - val_loss: 0.0874\n",
            "Epoch 184/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0162 - val_loss: 0.0809\n",
            "Epoch 185/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0169 - val_loss: 0.0885\n",
            "Epoch 186/200\n",
            "200/200 [==============================] - 26s 130ms/step - loss: 0.0165 - val_loss: 0.0842\n",
            "Epoch 187/200\n",
            "200/200 [==============================] - 27s 134ms/step - loss: 0.0170 - val_loss: 0.0853\n",
            "Epoch 188/200\n",
            "200/200 [==============================] - 27s 136ms/step - loss: 0.0159 - val_loss: 0.0899\n",
            "Epoch 189/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0157 - val_loss: 0.0962\n",
            "Epoch 190/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0163 - val_loss: 0.0927\n",
            "Epoch 191/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0153 - val_loss: 0.0860\n",
            "Epoch 192/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0164 - val_loss: 0.0880\n",
            "Epoch 193/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0159 - val_loss: 0.0866\n",
            "Epoch 194/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0155 - val_loss: 0.1029\n",
            "Epoch 195/200\n",
            "200/200 [==============================] - 27s 135ms/step - loss: 0.0160 - val_loss: 0.0926\n",
            "Epoch 196/200\n",
            "200/200 [==============================] - 27s 136ms/step - loss: 0.0150 - val_loss: 0.0913\n",
            "Epoch 197/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0157 - val_loss: 0.1022\n",
            "Epoch 198/200\n",
            "200/200 [==============================] - 26s 132ms/step - loss: 0.0157 - val_loss: 0.0804\n",
            "Epoch 199/200\n",
            "200/200 [==============================] - 26s 133ms/step - loss: 0.0149 - val_loss: 0.0729\n",
            "Epoch 200/200\n",
            "200/200 [==============================] - 26s 131ms/step - loss: 0.0149 - val_loss: 0.0837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval = model.evaluate(test_gen, steps = test_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80mbAC7Fj9rr",
        "outputId": "6a053e94-b1a1-4606-f377-75061277e3d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "510/510 [==============================] - 17s 33ms/step - loss: 0.0566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"drive/MyDrive/Engineer's Project/longer_prediction.h5\")"
      ],
      "metadata": {
        "id": "5kirxTc53zip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model(\"drive/MyDrive/Engineer's Project/standard_model.h5\")"
      ],
      "metadata": {
        "id": "n9qcEBR6inhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "vnLnO2_uCwlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(float_game_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZakESFxKUKU",
        "outputId": "adc7d98d-37e0-4693-9d25-cc819f7522b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "542"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_picks = 0\n",
        "value = 0\n",
        "for i in range(541-30): #len(float_train_data - lookback - delay\n",
        "  if len(float_game_data) <= 30:\n",
        "    break\n",
        "  last = float_train_data[-lookback:]\n",
        "  last = last.reshape(1,30,7)\n",
        "  prediction = model.predict(last)\n",
        "  last_val = last[0][lookback-1][3]\n",
        "  actual_val = float_game_data[30][3]\n",
        "  if((prediction > last_val) and (actual_val > last_val)):\n",
        "    correct_picks+=1\n",
        "    value += 100 * (actual_val - last_val)\n",
        "  elif((prediction < last_val) and (actual_val < last_val)):\n",
        "    correct_picks+=1\n",
        "    value += 100 * (last_val - actual_val)\n",
        "  else:\n",
        "    value -= 100 * abs(actual_val - last_val)\n",
        "  float_train_data = np.vstack((float_train_data, float_game_data[0]))\n",
        "  float_game_data = np.delete(float_game_data, 0, 0)"
      ],
      "metadata": {
        "id": "zhKV_vhVQTrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_picks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPy38h7MRhhU",
        "outputId": "b5b91fe2-f25f-4083-d4e3-01b70a28a536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6oMfj5RRmqU",
        "outputId": "e58aa4bd-f189-46f1-a263-bf91442958b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "327.56914496421814"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#updated model\n",
        "print(correct_picks)\n",
        "print(value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJqQrUnygk2Q",
        "outputId": "88c39d7e-05a4-4540-cf7c-3c92125cc6a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "298\n",
            "4589.046776294708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "version 2 updates the model"
      ],
      "metadata": {
        "id": "q2JVdmc-oJQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def return_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(layers.LSTM(120,\n",
        "    activation='sigmoid',\n",
        "    dropout=0.2,\n",
        "    recurrent_dropout=0.1,\n",
        "    input_shape=(None, float_train_data.shape[-1])))\n",
        "  model.add(layers.Dense(80,\n",
        "    activation='sigmoid',))\n",
        "  model.add(layers.Dense(1,\n",
        "    activation='sigmoid'))\n",
        "  model.compile(optimizer= tf.keras.optimizers.RMSprop(0.01), loss='mae')\n",
        "  return model"
      ],
      "metadata": {
        "id": "CnSFTESgoUf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(float_train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE3puJfNSTy5",
        "outputId": "40d0c739-a4f0-4ec9-cff0-61685e222e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "931"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_picks = 0\n",
        "value = 0\n",
        "for i in range(0,542-30):\n",
        "  if len(float_game_data) <= 30:\n",
        "    break\n",
        "  last = float_train_data[-lookback:]\n",
        "  last = last.reshape(1,30,7)\n",
        "  prediction = model.predict(last)\n",
        "  last_val = last[0][lookback-1][3]\n",
        "  actual_val = float_game_data[29][3]\n",
        "  if((prediction > last_val) and (actual_val > last_val)):\n",
        "    correct_picks+=1\n",
        "    value += 1000 * (actual_val - last_val)\n",
        "  elif((prediction < last_val) and (actual_val < last_val)):\n",
        "    correct_picks+=1\n",
        "    value += 1000 * (last_val - actual_val)\n",
        "  else:\n",
        "    value -= 1000 * abs(actual_val - last_val)\n",
        "  float_train_data = np.vstack((float_train_data, float_game_data[0]))\n",
        "  float_game_data = np.delete(float_game_data, 0, 0)\n",
        "\n",
        "  if i % 30 == 0:\n",
        "    del model\n",
        "    del train_gen\n",
        "    model = return_model()\n",
        "    train_gen = generator(float_train_data,\n",
        "      lookback=lookback,\n",
        "      delay=delay,\n",
        "      min_index=0,\n",
        "      max_index=len(float_train_data) - delay - 1,\n",
        "      #shuffle=True,\n",
        "      step=step,\n",
        "      batch_size=batch_size)\n",
        "    model.fit(train_gen,\n",
        "      steps_per_epoch=200,\n",
        "      epochs=20,\n",
        "      validation_data=val_gen,\n",
        "      validation_steps=val_steps)"
      ],
      "metadata": {
        "id": "VXxKSwYdoIa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de44f38-4a5b-4839-b7cb-16c6f4796a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "200/200 [==============================] - 25s 114ms/step - loss: 0.1046 - val_loss: 0.2210\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0801 - val_loss: 0.0763\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0647 - val_loss: 0.0771\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0606 - val_loss: 0.0909\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0576 - val_loss: 0.0949\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0558 - val_loss: 0.0779\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0554 - val_loss: 0.0815\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0539 - val_loss: 0.0836\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0533 - val_loss: 0.0788\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0531 - val_loss: 0.0839\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0520 - val_loss: 0.0824\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0516 - val_loss: 0.0761\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0512 - val_loss: 0.0836\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 25s 123ms/step - loss: 0.0541 - val_loss: 0.0821\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0499 - val_loss: 0.0760\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0498 - val_loss: 0.0856\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0550 - val_loss: 0.0912\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0502 - val_loss: 0.0770\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0529 - val_loss: 0.0828\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0495 - val_loss: 0.0830\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 25s 114ms/step - loss: 0.1031 - val_loss: 0.2369\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0806 - val_loss: 0.1188\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0669 - val_loss: 0.0805\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0610 - val_loss: 0.0932\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0580 - val_loss: 0.1080\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0560 - val_loss: 0.0787\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0558 - val_loss: 0.0883\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0539 - val_loss: 0.0837\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0537 - val_loss: 0.0792\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0539 - val_loss: 0.0826\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0524 - val_loss: 0.0867\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0523 - val_loss: 0.0772\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0517 - val_loss: 0.0812\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 25s 123ms/step - loss: 0.0508 - val_loss: 0.0874\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0503 - val_loss: 0.0748\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0502 - val_loss: 0.0776\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0498 - val_loss: 0.0958\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0523 - val_loss: 0.0738\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0500 - val_loss: 0.0803\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0485 - val_loss: 0.0807\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 25s 114ms/step - loss: 0.1153 - val_loss: 0.0985\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0849 - val_loss: 0.1153\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0687 - val_loss: 0.0715\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0653 - val_loss: 0.1010\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0616 - val_loss: 0.0609\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0610 - val_loss: 0.0714\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0593 - val_loss: 0.0630\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0603 - val_loss: 0.0872\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0594 - val_loss: 0.0698\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0575 - val_loss: 0.0760\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0599 - val_loss: 0.0899\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0565 - val_loss: 0.0801\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0573 - val_loss: 0.0835\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0556 - val_loss: 0.0739\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 24s 120ms/step - loss: 0.0556 - val_loss: 0.0929\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 24s 117ms/step - loss: 0.0548 - val_loss: 0.1044\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0541 - val_loss: 0.0792\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0537 - val_loss: 0.0839\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0594 - val_loss: 0.0626\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0620 - val_loss: 0.0957\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 26s 115ms/step - loss: 0.1222 - val_loss: 0.1031\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0858 - val_loss: 0.1451\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0697 - val_loss: 0.0604\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.0652 - val_loss: 0.1012\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0613 - val_loss: 0.0696\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0612 - val_loss: 0.0680\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0588 - val_loss: 0.0568\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0587 - val_loss: 0.0678\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0581 - val_loss: 0.0696\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0572 - val_loss: 0.0665\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0575 - val_loss: 0.0835\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0565 - val_loss: 0.0684\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0568 - val_loss: 0.0872\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0557 - val_loss: 0.0728\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 24s 122ms/step - loss: 0.0551 - val_loss: 0.0856\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 24s 117ms/step - loss: 0.0545 - val_loss: 0.1061\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0543 - val_loss: 0.0794\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0538 - val_loss: 0.1083\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0524 - val_loss: 0.0746\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0530 - val_loss: 0.1193\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 25s 116ms/step - loss: 0.1062 - val_loss: 0.0942\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0857 - val_loss: 0.1296\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0699 - val_loss: 0.0647\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0671 - val_loss: 0.0990\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0635 - val_loss: 0.0557\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0626 - val_loss: 0.0620\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0612 - val_loss: 0.0884\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0607 - val_loss: 0.0865\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0605 - val_loss: 0.1054\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0592 - val_loss: 0.0714\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0606 - val_loss: 0.1032\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0604 - val_loss: 0.0695\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0572 - val_loss: 0.0822\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0553 - val_loss: 0.0693\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 25s 124ms/step - loss: 0.0546 - val_loss: 0.0922\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0537 - val_loss: 0.1107\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0583 - val_loss: 0.0854\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0525 - val_loss: 0.1067\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0521 - val_loss: 0.0872\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0518 - val_loss: 0.0883\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 25s 116ms/step - loss: 0.1087 - val_loss: 0.0970\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0841 - val_loss: 0.1242\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0689 - val_loss: 0.0687\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0661 - val_loss: 0.0841\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0631 - val_loss: 0.0607\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.0626 - val_loss: 0.0963\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0606 - val_loss: 0.0972\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0601 - val_loss: 0.0662\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0598 - val_loss: 0.0672\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0584 - val_loss: 0.0607\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0582 - val_loss: 0.1015\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0567 - val_loss: 0.0720\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0565 - val_loss: 0.0877\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0562 - val_loss: 0.0809\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 25s 123ms/step - loss: 0.0551 - val_loss: 0.0945\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0541 - val_loss: 0.1030\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0535 - val_loss: 0.0913\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0535 - val_loss: 0.0917\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0524 - val_loss: 0.0744\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0529 - val_loss: 0.0998\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 26s 116ms/step - loss: 0.1184 - val_loss: 0.0965\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0839 - val_loss: 0.1169\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0691 - val_loss: 0.0587\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0654 - val_loss: 0.1019\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0617 - val_loss: 0.0599\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0652 - val_loss: 0.0676\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0614 - val_loss: 0.0711\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0603 - val_loss: 0.0723\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0597 - val_loss: 0.0654\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0586 - val_loss: 0.0687\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0583 - val_loss: 0.0756\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 23s 115ms/step - loss: 0.0570 - val_loss: 0.0693\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0579 - val_loss: 0.0992\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0559 - val_loss: 0.0965\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0555 - val_loss: 0.0997\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 25s 125ms/step - loss: 0.0550 - val_loss: 0.0874\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0547 - val_loss: 0.0760\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0539 - val_loss: 0.0733\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0531 - val_loss: 0.0747\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0538 - val_loss: 0.1888\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 26s 117ms/step - loss: 0.0928 - val_loss: 0.1141\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0807 - val_loss: 0.0915\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0728 - val_loss: 0.0869\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0678 - val_loss: 0.0861\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0649 - val_loss: 0.0821\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0622 - val_loss: 0.0785\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0605 - val_loss: 0.0818\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0592 - val_loss: 0.0918\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0583 - val_loss: 0.0930\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0577 - val_loss: 0.0718\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0568 - val_loss: 0.0787\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0563 - val_loss: 0.0707\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0556 - val_loss: 0.0800\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0549 - val_loss: 0.0907\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0545 - val_loss: 0.0926\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0533 - val_loss: 0.0822\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.0520 - val_loss: 0.0773\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0516 - val_loss: 0.0906\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0511 - val_loss: 0.0964\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0500 - val_loss: 0.0872\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 26s 118ms/step - loss: 0.0916 - val_loss: 0.0989\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0838 - val_loss: 0.1089\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0835 - val_loss: 0.1090\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0835 - val_loss: 0.1090\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0835 - val_loss: 0.1088\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0835 - val_loss: 0.1089\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0835 - val_loss: 0.1089\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0835 - val_loss: 0.1089\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0835 - val_loss: 0.1090\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0835 - val_loss: 0.1088\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0835 - val_loss: 0.1088\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0835 - val_loss: 0.1089\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 23s 118ms/step - loss: 0.0835 - val_loss: 0.1089\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0835 - val_loss: 0.1089\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0835 - val_loss: 0.1090\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0835 - val_loss: 0.1088\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 25s 126ms/step - loss: 0.0835 - val_loss: 0.1088\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0835 - val_loss: 0.1089\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0835 - val_loss: 0.1089\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0835 - val_loss: 0.1090\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 26s 119ms/step - loss: 0.1013 - val_loss: 0.1137\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0768 - val_loss: 0.1078\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0703 - val_loss: 0.0972\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0648 - val_loss: 0.0905\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0624 - val_loss: 0.0871\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0610 - val_loss: 0.0982\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0599 - val_loss: 0.1000\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0592 - val_loss: 0.1021\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0585 - val_loss: 0.0710\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0581 - val_loss: 0.0962\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0575 - val_loss: 0.0738\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0570 - val_loss: 0.1000\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0565 - val_loss: 0.0776\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0560 - val_loss: 0.0778\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 25s 126ms/step - loss: 0.0556 - val_loss: 0.1080\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0550 - val_loss: 0.1082\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0546 - val_loss: 0.1054\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 23s 118ms/step - loss: 0.0544 - val_loss: 0.0805\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0535 - val_loss: 0.0894\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0533 - val_loss: 0.0763\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 26s 119ms/step - loss: 0.0922 - val_loss: 0.1139\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0798 - val_loss: 0.0912\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0729 - val_loss: 0.0854\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0677 - val_loss: 0.0849\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0649 - val_loss: 0.0883\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0628 - val_loss: 0.0818\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0605 - val_loss: 0.0834\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0591 - val_loss: 0.0761\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0580 - val_loss: 0.0884\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0572 - val_loss: 0.0797\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0564 - val_loss: 0.0679\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0556 - val_loss: 0.0780\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 25s 125ms/step - loss: 0.0546 - val_loss: 0.0961\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0546 - val_loss: 0.0938\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0533 - val_loss: 0.0960\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0530 - val_loss: 0.0828\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0524 - val_loss: 0.0780\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0515 - val_loss: 0.0898\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0506 - val_loss: 0.0868\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0587 - val_loss: 0.0920\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 26s 117ms/step - loss: 0.0874 - val_loss: 0.1668\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0774 - val_loss: 0.1305\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0776 - val_loss: 0.1079\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0777 - val_loss: 0.1098\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0781 - val_loss: 0.1304\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0775 - val_loss: 0.1444\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0774 - val_loss: 0.1194\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0778 - val_loss: 0.1034\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0773 - val_loss: 0.1162\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0784 - val_loss: 0.1438\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0771 - val_loss: 0.1304\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 25s 126ms/step - loss: 0.0776 - val_loss: 0.1078\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0777 - val_loss: 0.1100\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0781 - val_loss: 0.1303\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0775 - val_loss: 0.1446\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0774 - val_loss: 0.1193\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0778 - val_loss: 0.1034\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0773 - val_loss: 0.1163\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0784 - val_loss: 0.1440\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0771 - val_loss: 0.1306\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 26s 118ms/step - loss: 0.0936 - val_loss: 0.1972\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0719 - val_loss: 0.1097\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0734 - val_loss: 0.0758\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0667 - val_loss: 0.0832\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 23s 118ms/step - loss: 0.0645 - val_loss: 0.1392\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0617 - val_loss: 0.1053\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0597 - val_loss: 0.0692\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0588 - val_loss: 0.0629\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0573 - val_loss: 0.1051\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 25s 126ms/step - loss: 0.0571 - val_loss: 0.1107\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0554 - val_loss: 0.0879\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0549 - val_loss: 0.0694\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 23s 118ms/step - loss: 0.0544 - val_loss: 0.0640\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0535 - val_loss: 0.1174\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0532 - val_loss: 0.0995\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0519 - val_loss: 0.0703\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0523 - val_loss: 0.0712\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0513 - val_loss: 0.0838\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0503 - val_loss: 0.0866\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0495 - val_loss: 0.0880\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 26s 119ms/step - loss: 0.0947 - val_loss: 0.1916\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 23s 118ms/step - loss: 0.0709 - val_loss: 0.0921\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0710 - val_loss: 0.0718\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0664 - val_loss: 0.0883\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 23s 116ms/step - loss: 0.0646 - val_loss: 0.1501\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0620 - val_loss: 0.1090\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0602 - val_loss: 0.0750\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 25s 126ms/step - loss: 0.0593 - val_loss: 0.0566\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0587 - val_loss: 0.0981\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0584 - val_loss: 0.1243\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0574 - val_loss: 0.0816\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0570 - val_loss: 0.0791\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0569 - val_loss: 0.0744\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0561 - val_loss: 0.1212\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0551 - val_loss: 0.0891\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0544 - val_loss: 0.0882\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0543 - val_loss: 0.0882\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0539 - val_loss: 0.1008\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0528 - val_loss: 0.0985\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0516 - val_loss: 0.0784\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 26s 119ms/step - loss: 0.0875 - val_loss: 0.1964\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0708 - val_loss: 0.0950\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0707 - val_loss: 0.0737\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0666 - val_loss: 0.0874\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 25s 126ms/step - loss: 0.0635 - val_loss: 0.1483\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0616 - val_loss: 0.1100\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0597 - val_loss: 0.0693\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0589 - val_loss: 0.0593\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0583 - val_loss: 0.0966\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0578 - val_loss: 0.1203\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0568 - val_loss: 0.0933\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0566 - val_loss: 0.0744\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0565 - val_loss: 0.0982\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0563 - val_loss: 0.1290\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0556 - val_loss: 0.1082\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0551 - val_loss: 0.0861\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0552 - val_loss: 0.0840\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0547 - val_loss: 0.0859\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0544 - val_loss: 0.0997\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0531 - val_loss: 0.0844\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 26s 120ms/step - loss: 0.1005 - val_loss: 0.0802\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0830 - val_loss: 0.0868\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0789 - val_loss: 0.0767\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0706 - val_loss: 0.0763\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0681 - val_loss: 0.0686\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0662 - val_loss: 0.0641\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0698 - val_loss: 0.0774\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0646 - val_loss: 0.0613\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0652 - val_loss: 0.0716\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0629 - val_loss: 0.0662\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0618 - val_loss: 0.0687\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0607 - val_loss: 0.0584\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0600 - val_loss: 0.0664\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0592 - val_loss: 0.0663\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0587 - val_loss: 0.0671\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0583 - val_loss: 0.0658\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0580 - val_loss: 0.0741\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0596 - val_loss: 0.0661\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.0576 - val_loss: 0.0727\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0574 - val_loss: 0.0759\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 26s 120ms/step - loss: 0.1018 - val_loss: 0.0802\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0828 - val_loss: 0.0959\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0806 - val_loss: 0.1043\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0799 - val_loss: 0.1051\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 23s 117ms/step - loss: 0.0799 - val_loss: 0.1031\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0790 - val_loss: 0.0850\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0757 - val_loss: 0.0744\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0745 - val_loss: 0.0702\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0706 - val_loss: 0.0767\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0677 - val_loss: 0.0686\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0665 - val_loss: 0.0823\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0654 - val_loss: 0.0718\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0651 - val_loss: 0.0593\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0642 - val_loss: 0.0685\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 26s 128ms/step - loss: 0.0636 - val_loss: 0.0805\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0631 - val_loss: 0.0788\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 24s 120ms/step - loss: 0.0634 - val_loss: 0.0691\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0618 - val_loss: 0.0656\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0612 - val_loss: 0.0648\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 24s 120ms/step - loss: 0.0621 - val_loss: 0.0665\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 26s 119ms/step - loss: 0.1061 - val_loss: 0.0716\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0887 - val_loss: 0.0797\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0832 - val_loss: 0.0847\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0776 - val_loss: 0.0806\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0708 - val_loss: 0.0796\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0675 - val_loss: 0.0765\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0661 - val_loss: 0.0794\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0646 - val_loss: 0.0657\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0639 - val_loss: 0.0752\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0630 - val_loss: 0.0739\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 25s 127ms/step - loss: 0.0626 - val_loss: 0.0703\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0622 - val_loss: 0.0566\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0617 - val_loss: 0.0577\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0610 - val_loss: 0.0581\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0608 - val_loss: 0.0521\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0601 - val_loss: 0.0572\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0597 - val_loss: 0.0717\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 24s 120ms/step - loss: 0.0589 - val_loss: 0.0654\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 24s 118ms/step - loss: 0.0585 - val_loss: 0.0765\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 24s 119ms/step - loss: 0.0580 - val_loss: 0.0733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_picks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mcgPRTL0ODn",
        "outputId": "8827753a-2283-4cf8-a77b-ff4bb0891893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "272"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePLbVBoW0Rjx",
        "outputId": "fb34cc41-8580-430b-838a-3c8e34cf5ef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "875.434935092926"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}